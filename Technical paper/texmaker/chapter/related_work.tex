%!TEX root = ../Technical_paper.tex
\section{Realted work}
\label{sec:realted_work}
There have been several different approaches on solving the the tracking of the human hands with their maximum of 27 DoF's each.
The systems that try to achieve this have to encounter several difficulties. Self occlusion plays a great role in the system design, especially when working with only one tracking optical system for reduced complexity. Also these systems need to maintain a certain amount of processing speed for achieving a fluent reproduction of the captured motion. This demands the capability of processing large amounts of data in very short intervals. Most prototype testing for the described systems is done in an controlled environment where the background is known. For a more widespread use, these systems need to be capable of registering the hand on an unrestricted background, which may have a wide range of patterns, color and lighting differences. Also human hand motion itself is quite fast, resulting in a higher frame rate demand for the tracking cameras.\\
Early hand tracking systems, dating back to the 1970's \cite{ThomasA.DeFanti.1977,Grimes.1983}, relied on glove systems which used different forms of electronic sensors to measure finger and hand positioning. Newer systems made use of the developements in electronic part size and reduced the mounted sensors sizes\cite{Kuroda.2004,HernandezRebollar.2002}
Further readings on sensor based hand tracking systems can be found in \cite{Dipietro.2008,Sturman.1994}.\\
With more processing capabilites at hand optical tracking approaches where also evaluated\cite{Duca.2007,Fredriksson.2008,Wang.2009}. These systems take either monocular or stereoscopic images of the hand and process these afterwards to find the hand position. To get a hand tracking from pure visual data, these approaches all use colored marker on gloves. The approaches vary from only colored fingertips\cite{Fredriksson.2008} of the glove to fully patterned gloves\cite{Wang.2009} where the known patter is used for pose estimation. Data retrieved from these markers are then compared against databases of recorded hand position configurations to find a nearest match.\\
The currently most used type of system for tracking hardware is a setup of a combination of RGB and infrared sensors for imaging an depth measurement (RGB-D)\cite{Zhang.2012,Weichert.2013,IntelCorporation.2018}. The RGB-D camera systems are now capable of suppling image data at up to 90fps. The post processing of this data needs more sophisticated image analysis or neural network processing to figure out feature points of the tracked object from the supplied image data\cite{JamieShotton.2011,Oikonomidis.2011b}.\\
Such an approach of combining RGB-D Data and the usage of CNNs (Convolutional Neural Networks) to estimate hand pose and render a correct digital representaion of the hand is shown in \cite{FranziskaMueller.2017}.
\\Their approach uses two subsequently applied CNNs to localize the hand and regress 3D joint locations. The first CNN estimates the 2D position of the hand center in the input. The combined information of the hand position together with the corresponding input depth value, is used to generate a normalized cropped image. this image is then fed into a second CNN to regress relative 3D hand joint
locations in real time. Pose estimation is furthermore refined by using a kinematic pose tracking energy to achieve more accuracy, robustness and
temporal stability.
\\They also introduce a new photo-realistic data set that uses a merged reality
approach to capture and synthesize large amounts of annotated
data of natural hand interaction in cluttered scenes for CNN training data.