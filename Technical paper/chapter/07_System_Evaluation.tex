%!TEX root = ../Technical_paper.tex
\section{System Evaluation}
\subsection{Camera hardware and control}
The image  processing of the camera frames on the raspberry can be a significant bottleneck for the system. With the current system setup running at 30fps, this means that the image processing time, containing frame readout and downstream processing of the images, has to be done in about $1/30s$ or 33 ms to achieve "real time" processing. The cameras use a rolling shutter instead of a global shutter. Since these cameras are designed to be of easy use for the normal consumer, they lack means of external synchronization. Attempting the synchronization of the data via Software further down the processing pipeline is therefore more reasonable.
\\To synchronize the reading start point of both cameras the system boots up to the point where all needed components are initialized. At this point the program waits for a start message from the parent system via UDP. The parent system send the start message at the end of its initialization phase via a UDP broadcast, ensuing that both Raspberry's get the message at the same time.\\
All automatic modes are turned of in the camera initialization phase and fixed values are loaded from a JSON file. To get the values for the JSON file a calibration step was implemented into the command line tool. The user-set calibration values can be written into a new JSON file and are directly loaded into the program after calibration is finished. Control over these parameters is crucial for achieving a constant color separation. The threshold values values for the color tracking also need to be initially calibrated. These values are dependent on the lighting situation and any change results in the need for re-calibration. To simplify this calibration a calibration function in the same fashion as the camera calibration was implemented.
\section{Image processing performance}
Initial investigation into code timings showed, that a bottleneck was the image optimization feature which applied an erosion an dilation to remove high frequency noise in the image. This operation brought the time up to 100 ms processing time when processing the whole frame area, making the algorithm  not usable for "real time" application.Removing this feature for whole image scans brought a major speed up in processing time. 
A test with lower resolution than 640x480 showed that the calculation time can be reduced furthermore. This confirmed that the ROI idea would be feasible for further performance optimization. A test at a frame resolution of 320x240 pixels reduced the processing time for all five colors to below 10 ms.\\
Performance measurement for tracking consistency with stationary color trackers was performed for a time period of 10.000 frames to get qualitative results. The sequential implementation showed an average processing time of 46 ms with a standard deviation of ~11 ms.
The same measurement were done with a finer time tracking on the single parts of the processing pipeline to get a finer timing resolution. 96\% of the processing time is taken up by the image stereo rectification (31 ms) and the color tracking(15 ms ).\\
Stereo rectification is usually done to ensure that the two used images have an aligned horizontal orientation with camera pairs that are not aligned horizontally and/or parallel. Since the camera setup ensures this, the rectification step can be omitted for performance reasons. It cuts down 67\% of the processing time of the system. As the stereo calculation does not use the vertical position difference for calculations, the possible resulting differences can be dealt with via filtering on the receiver side.
The resulting timing values showed to be sufficient to supply a tracking data stream of around 12 to 14 ms processing time with a sequential calculation approach.
\subsection{COLOR ACCURACY AND ROI SIZE}
Variations of lighting intensity and color temperature  can cause the color of the trackers to shift their color. This can cause a fluctuation in the calculated tracker positions, as the defined color threshold ranges are kept as small as possible to achieve a clean separation of the tracker colors and reduce unwanted noise. \\
System testing with 5 different colored markers showed, that tracking for colors outside of the color range of the human skin tones (green,blue) is rather unproblematic. The color markers falling into the colorspace of possible light reflection from skin may cause problems, depending on the lighting situation of the setup.
\\Figure \ref{img:Color_reflecton_problems} displays such a case where depending on the orientation of the hand, refletion from the scenery lightng can fall int the color tone space of the tracked marker, causing large parts of the hand to light up in the image. Since the calculation of the tracking marker position relies on finding the largest closed "white" area in the thresholded image, this can cause a "jumping" of the calculated position.
Acrylic paint is available in many color variations, making it possible to stay outide of the skintone color ranges for the marker colors.It showed to have the benefits of being easily to apply to the finger. The finger coating is dry in under a minute after application. Adaption for finger size is automatically included in the application process.  
\\\\The implemented ROI feature speed up the whole system calculations once the colors are found. Before this point, the system scans whole frames to find colors, which takes more time than the much smaller ROI regions.
Empirical evaluations showed, that for the used tracking space, a ROI region size offset of 40 px in x and y directions produces the best results in terms of consistency. Smaller region offsets caused the system to use tracking for faster hand motion, which causes system slow down until the tracking has recovered. Generally, larger ROI's produce more constent tracking results at the cost of higher calculation time.
\begin{figure}[H]
\includegraphics[scale=0.05]{images/final_finger_markers.jpg}
\centering
\caption{Finger marked with suitable acrylic colors}
\label{img:final_markers}
\end{figure}
For the colors a mixture of blue and green color tones together with red tones in the purple and magenta section were chosen as the final colors.
\subsection{Depth measurement accuracy}
To determine the accuracy of the system for it's depth measurement values a simple test bench setup was used. The camera rig was aligned horizontally and fixed to a test bench. A large sized colored marker (75 mm x 50 mm) was used as target for detection. The marker was positioned at altering distances from the camera rig along the it's central axis. The height at which the camera rig is positioned in the prototype setup will be around 100 cm, so the measured distances started at 100 cm from the camera and were decremented in steps of 5 cm until 20 cm in front of the camera rig.
The accuracy of the camera system is limited by the number of pixels in relation to the camera view angleas described in \cite{JernejMrovlje.2008}.For the system setup of 640 px image width and a horizontal view angle of $62.5^\circ$, $\Delta\varphi$ is equal to $0.0977\frac{1^\circ}{pixel}$.The system error for a $D=100cm$ would therefore result in about $2cm$ of possible error.As the measured values showed deviations of up to $5\%$ from the correct value a correcting function \cite{ManafA.Mahammed.2013} was applied for the depth calculation. The depth value is calculated as:
\begin{equation}
\label{equ:power_function}
D=k*x^{z}
\end{equation}
with K being:
\begin{equation}
k=\frac{Bx_0}{2\tan(\frac{\varphi_0}{2}+\phi)}
\end{equation}
and x the disparity in pixels.
The $\phi$ term in the equation above is used as a compensation for possible alignment errors.
A exponential trendline fitted to the measured results represents the the function needed to fulfill equation above.The calculated values for the system are $k=4543.3$ and $z=-1.035$.
With the utilization of the correction function, the accuracy of the depth measurement are acceptable for the prototype application.
\section{Data filtering}
Measurements for of the base jitter in the data for the finger markers showed that the systems can only supply a certain stability of position tracking, causing fluctuations in the position results.Jittering of position values also causes the height calculation algorithm to generate incorrect height values.\\
To get mor stable a results, a filtering of the incoming data-set in several steps with the \textit{1 euro filter} presented by Casiez et al. \cite{Casiez.2012} needs to be applied.It uses a first order low-pass filter with an adaptive cutoff frequency to filter noisy signals for high precision and responsiveness.The filter was chosen, beacuase of a relative simple and easy implementation as well as an uncomplicated setup and tuning process. It also produces faster and better results in comparsion to the normally used \textit{Kalman filter}\cite{Welch.2001}, \textit{moving average filter} or \textit{low-pass filters and exponential smoothing filter}s\cite{LaViola.2003}.
\section{Inverse kinematics algorithm}
Figure \ref{img:hand-constraint_debug_view} shows debugging representations of the used kinematic structure in the \textit{Caliko} framework.
\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth/2]{images/hand_model_combo.png}
\caption{Hand model representatio of the used IK Framework: a) Kinematic chains and base structure, b) hand model with visualized movement constraints}
\label{img:hand-constraint_debug_view} 
\end{figure} 
It differentiates between base bone constraints and normal bone constraints.The constraints can be applied with either a global or a local reference axis.The reference axis can the be used for the specific type of constraint. The framework supports hinge type constraints ( 1DOF ) and rotor constraints ( 2DOF ). For the rotor constraints only circular curve limitations can be defined. This is a downside of the framework as a parabolic curve description for a rotor-based constraint would better fit the movement capabilities of the fingers.