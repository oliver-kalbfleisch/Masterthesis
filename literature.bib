% This file was created with Citavi 5.7.0.0

@misc{.,
 abstract = {Vision can be a powerful interface device for computers because of its potential for sensing body position, head orientation, direction of gaze, pointing c},
 title = {Computer vision for interactive computer graphics - IEEE Xplore Document},
 url = {http://ieeexplore.ieee.org/abstract/document/674971/},
 urldate = {2017-08-13}
}


@proceedings{.1984,
 year = {1984},
 title = {The 23rd IEEE Conference on Decision and Control},
 publisher = {IEEE}
}


@article{.1984b,
 year = {1984},
 title = {Robust Control of Robotic Manipulators},
 pages = {2435--2440},
 pagination = {page},
 volume = {17},
 number = {2},
 issn = {1474-6670},
 journal = {IFAC Proceedings Volumes},
 doi = {10.1016/S1474-6670(17)61347-8}
}


@proceedings{.2001,
 year = {2001},
 title = {BMVC}
}


@proceedings{.2007,
 year = {2007},
 title = {Proceedings of the Workshop at the IEEE Virtual Reality 2007 Conference; Trends and Issues in Tracking for Virtual Environments}
}


@proceedings{.2014,
 year = {2014},
 title = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}


@misc{.b,
 abstract = {A method is proposed that can generate a ranked list of plausible three-dimensional hand configurations that best match an input image. Hand pose estimatio},
 title = {Estimating 3D hand pose from a cluttered image - IEEE Xplore Document},
 url = {http://ieeexplore.ieee.org/abstract/document/1211500/},
 urldate = {2017-08-13}
}


@misc{.c,
 abstract = {We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery},
 title = {Sharing Visual Features for Multiclass and Multiview Object Detection - IEEE Xplore Document},
 url = {http://ieeexplore.ieee.org/abstract/document/4135679/},
 urldate = {2017-08-13}
}


@misc{.d,
 abstract = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they},
 title = {Snakes: Active contour models},
 url = {https://link.springer.com/article/10.1007%2FBF00133570?LI=true},
 urldate = {2017-08-17}
}


@misc{.e,
 abstract = {We present a nonintrusive system based on computer vision for human-computer interaction in three-dimensional (3-D) environments controlled by hand pointin},
 title = {Visual capture and understanding of hand pointing actions in a 3-D environment - IEEE Xplore Document},
 url = {http://ieeexplore.ieee.org/abstract/document/1213560/},
 urldate = {2017-08-13}
}


@book{12THAnnualConferenceonComputerGraphics1985.1985,
 year = {1985},
 title = {Proceedings of the 12th annual conference on Computer graphics and interactive techniques},
 keywords = {Computer science},
 address = {New York, NY},
 urldate = {2017-09-22},
 publisher = {ACM},
 institution = {{12TH Annual Conference on Computer Graphics 1985} and {ACM Special Interest Group on Computer Graphics and Interactive Techniques}}
}


@proceedings{ACM.2009,
 year = {2009},
 title = {ACM transactions on graphics (TOG)},
 institution = {ACM}
}


@article{Alemzadeh.,
 author = {Alemzadeh, Milad},
 title = {Human-Computer Interaction: An Overview},
 urldate = {2017-08-17}
}


@article{AndreasAristidouandJoanLasenby.,
 author = {{Andreas Aristidou and Joan Lasenby}},
 title = {Inverse Kinematics: a review of existing techniques and introduction of a new fast iterative solver},
 keywords = {Inverse Kinematics FABRIK Joint configuration CCD Jacobian Inverse},
 urldate = {2017-09-14}
}


@inproceedings{Aristidou.2010,
 author = {Aristidou, Andreas and Lasenby, Joan},
 title = {Motion capture with constrained inverse kinematics for real-time hand tracking},
 keywords = {Augmented reality;Hand tracking;motion capture;User Interface},
 pages = {1--5},
 bookpagination = {page},
 booktitle = {Communications, Control and Signal Processing (ISCCSP), 2010 4th International Symposium on},
 year = {2010}
}


@article{Aristidou.2011,
 abstract = {GRAPHICAL MODELS, 73 (2011) 243-260. doi:10.1016/j.gmod.2011.05.003},
 author = {Aristidou, Andreas and Lasenby, Joan},
 year = {2011},
 title = {FABRIK: A fast, iterative solver for the Inverse Kinematics problem},
 keywords = {Human animation;Inverse Kinematics;Joint configuration;Motion reconstruction},
 urldate = {2017-09-14},
 pages = {243--260},
 pagination = {page},
 volume = {73},
 number = {5},
 issn = {15240703},
 journal = {Graphical Models},
 doi = {10.1016/j.gmod.2011.05.003}
}


@article{Aristidou.2013,
 abstract = {Optical motion capture systems suffer from marker

occlusions resulting in loss of useful information. This

paper addresses the problem of real-time joint localisation

of legged skeletons in the presence of such missing data.

The data is assumed to be labelled 3d marker positions from

a motion capture system. An integrated framework is presented

which predicts the occluded marker positions using

a Variable Turn Model within an Unscented Kalman filter.

Inferred information from neighbouring markers is used

as observation states; these constraints are efficient, simple,

and real-time implementable. This work also takes advantage

of the common case that missing markers are still

visible to a single camera, by combining predictions with

under-determined positions, resulting in more accurate predictions.

An Inverse Kinematics technique is then applied

ensuring that the bone lengths remain constant over time;

the system can thereby maintain a continuous data-flow. The

marker and Centre of Rotation (CoR) positions can be calculated

with high accuracy even in cases where markers

are occluded for a long period of time. Our methodology is

tested against some of the most popular methods for marker

prediction and the results confirm that our approach outperforms

these methods in estimating both marker and CoR positions.},
 author = {Aristidou, Andreas and Lasenby, Joan},
 year = {2013},
 title = {Real-time marker prediction and CoR estimation in optical motion capture},
 urldate = {2017-08-25},
 pages = {7--26},
 pagination = {page},
 volume = {29},
 number = {1},
 issn = {0178-2789},
 journal = {The Visual Computer},
 doi = {10.1007/s00371-011-0671-y}
}


@article{Badler.1987,
 author = {Badler, Norman and Manoochehri, Kamran and Walters, Graham},
 year = {1987},
 title = {Articulated Figure Positioning by Multiple Constraints},
 keywords = {Constraints},
 urldate = {2017-09-15},
 pages = {28--38},
 pagination = {page},
 volume = {7},
 number = {6},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/MCG.1987.276894}
}


@article{Besl.1988,
 author = {Besl, P. J.},
 year = {1988},
 title = {Geometric modeling and computer vision},
 urldate = {2017-08-17},
 pages = {936--958},
 pagination = {page},
 volume = {76},
 number = {8},
 issn = {00189219},
 journal = {Proceedings of the IEEE},
 doi = {10.1109/5.5966}
}


@article{Cootes.1995,
 author = {Cootes, Timothy F. and Taylor, Christopher J. and Cooper, David H. and Graham, Jim},
 year = {1995},
 title = {Active shape models-their training and application},
 pages = {38--59},
 pagination = {page},
 volume = {61},
 number = {1},
 journal = {Computer vision and image understanding}
}


@book{Dahmen.2008,
 author = {Dahmen, Wolfgang and Reusken, Arnold},
 year = {2008},
 title = {Numerik f{\"u}r Ingenieure und Naturwissenschaftler},
 url = {http://dx.doi.org/10.1007/978-3-540-76493-9},
 keywords = {Lehrbuch;Numerische Mathematik;Online-Publikation},
 address = {Berlin Heidelberg},
 edition = {Zweite, korrigierte Auflage},
 publisher = {{Springer-Verlag Berlin Heidelberg}},
 isbn = {9783540764939},
 series = {Springer-Lehrbuch}
}


@inproceedings{Duca.2007,
 abstract = {The purpose of this project is to create a library that will allow its users to control 3D applications by using one or both of their hands. The final product could easily be incorporated into 3D applications, each customized to utilize a set of poses. Even though off-the-shelf motion capture gloves have reached lower prices in recent years, they are still expensive for home users. The algorithm suggested is based only on a single webcam combined with coded palm and fingers. Users should be able to code one or more of the fingers. One webcam is still somewhat constraining as two should ideally be used for 3D mapping of the hand, but by additionally using palm and finger coding we can greatly improve precision and, most importantly, reduce the processing power required for feasible real-time 3D interaction.},
 author = {Duca, Florin and Fredriksson, Jonas and Fjeld, Morten},
 title = {Real-time 3d hand interaction: Single webcam low-cost approach},
 pages = {1--5},
 bookpagination = {page},
 booktitle = {Proceedings of the Workshop at the IEEE Virtual Reality 2007 Conference; Trends and Issues in Tracking for Virtual Environments},
 year = {2007}
}


@article{ElSawah.2008,
 author = {El-Sawah, Ayman and Georganas, Nicolas D. and Petriu, Emil M.},
 year = {2008},
 title = {A prototype for 3-D hand tracking and posture estimation},
 pages = {1627--1636},
 pagination = {page},
 volume = {57},
 number = {8},
 journal = {IEEE Transactions on Instrumentation and Measurement}
}


@article{Erol.2007,
 author = {Erol, Ali and Bebis, George and Nicolescu, Mircea and Boyle, Richard D. and Twombly, Xander},
 year = {2007},
 title = {Vision-based hand pose estimation: A review},
 pages = {52--73},
 pagination = {page},
 volume = {108},
 number = {1-2},
 journal = {Computer vision and image understanding},
 doi = {10.1016/j.cviu.2006.10.012}
}


@inproceedings{Fredriksson.2008,
 abstract = {This paper presents a low-cost method for enabling 3D handcomputer interaction. The method, accompanied by a system, uses the frame capturing functionality of a single consumer-grade webcam. Our recent work has been focused on examining and realizing a less complex system. The presented method reduces the tracking effort to only one reference marker: a color-coded bracelet that helps locate the part of the captured frame containing the user's hand. The located area contains all the information needed to extract hand rotation and finger angle data. To facilitate hand feature extraction, we have outfitted the user's hand with a specially coded glove. The glove is equipped with two square palm markers, a marker on either side of the hand, and five distinctly shaded finger sheaths. We believe that an approach that only tracks only one marker will be more efficient than similar methods that track each finger separately. The method is further simplified by using spatial properties, drawn from physiological characteristics of the human hand, to limit the areas considered by the algorithm. Some challenges regarding webcam limitations may arise when attempting to carry this method into effect, including problems related to image noise and limited image- and color-resolution. Overlapping hands and fingers, hand positioning outside the field of view, and interference by local light sources are other exigent factors to consider.},
 author = {Fredriksson, Jonas and Ryen, Sven Berg and Fjeld, Morten},
 title = {Real-time 3D hand-computer interaction},
 keywords = {3D Hand-Computer Interaction;3D Interaction;3D Navigation;Gesture;Mixed Reality},
 pages = {133},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {9781595937049},
 editor = {Tollmar, Konrad},
 booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction building bridges},
 year = {2008},
 address = {New York, NY},
 doi = {10.1145/1463160.1463175}
}


@article{G.R.S.MurthyR.S.Jadon.JulyDecember2009,
 abstract = {{\th}ÿ},
 author = {{G. R. S. Murthy,R. S. Jadon}},
 year = {July-December 2009},
 title = {A REVIEW OF VISION BASED HAND GESTURES RECOGNITION},
 urldate = {2017-08-17},
 pages = {405--410},
 pagination = {page},
 number = {2},
 journal = {International Journal of Information Technology and Knowledge Management}
}


@article{Gonzalez.2015,
 author = {Gonzalez, Franck and Gosselin, Florian and Bachta, Wael},
 year = {2015},
 title = {A 2-D Infrared Instrumentation for Close-Range Finger Position Sensing},
 pages = {2708--2719},
 pagination = {page},
 volume = {64},
 number = {10},
 journal = {IEEE Transactions on Instrumentation and Measurement}
}


@inproceedings{Henia.2011,
 author = {Henia, Ouissem Ben and Bouakaz, Saida},
 title = {3D Hand model animation with a new data-driven method},
 pages = {72--76},
 bookpagination = {page},
 booktitle = {Digital Media and Digital Content Management (DMDCM), 2011 Workshop on},
 year = {2011}
}


@book{IEEE.1995,
 abstract = {In this work, the authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression. The model is able to fitted to any person's hand and can be done using a single camera. Once the model is fitted to a real human hand, it is then used in several tracking scenarios in order to verify its effectiveness. With successful tracking achieved, the model is ready to be incorporated into a virtual environment or model based compression scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks at very low bit rates and at very high image quality.},
 author = {IEEE},
 year = {1995},
 title = {Proceedings: Fifth International Conference on Computer Vision, June 20-23, 1995, Massachusetts Institute of Technology, Cambridge, Massachusetts},
 keywords = {Computer vision;Congresses},
 address = {Los Alamitos, Calif},
 urldate = {2017-09-07},
 publisher = {{IEEE Computer Society Press}},
 institution = {{International Conference on Computer Vision} and {IEEE Computer Society}}
}


@proceedings{IEEE.2008,
 year = {2008},
 title = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2009,
 year = {2009},
 title = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2009b,
 year = {2009},
 title = {Computer-Aided Design and Computer Graphics, 2009. CAD/Graphics' 09. 11th IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2010,
 year = {2010},
 title = {Communications, Control and Signal Processing (ISCCSP), 2010 4th International Symposium on},
 institution = {IEEE}
}


@proceedings{IEEE.2011,
 year = {2011},
 title = {Automatic Face {\&} Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2011b,
 year = {2011},
 title = {Digital Media and Digital Content Management (DMDCM), 2011 Workshop on},
 institution = {IEEE}
}


@proceedings{IEEE.2011c,
 year = {2011},
 title = {Multimedia and Expo (ICME), 2011 IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2013,
 year = {2013},
 title = {Digital Image Computing: Techniques and Applications (DICTA), 2013 International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2017,
 year = {2017},
 title = {Virtual Reality (VR), 2017 IEEE},
 institution = {IEEE}
}


@proceedings{InstituteofElectricalandElectronicsEngineers.2008,
 year = {2008},
 title = {IEEE Conference on Computer Vision and Pattern Recognition, 2008: CVPR 2008 ; Anchorage, AK, 23 - 28 June 2008},
 keywords = {Computer vision;Congresses;Kongress;Maschinelles Sehen;Mustererkennung;Pattern recognition systems},
 address = {Piscataway, NJ},
 publisher = {{IEEE Service Center}},
 isbn = {978-1-4244-2242-5},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Conference on Computer Vision and Pattern Recognition} and CVPR}
}


@book{InstituteofElectricalandElectronicsEngineers.2008b,
 year = {2008},
 title = {2008 8th IEEE International Conference on Automatic Face {\&} Gesture Recognition: FG 2008 ; Amsterdam, Netherlands, 17 - 19 September 2008},
 keywords = {Gesicht;Mustererkennung},
 address = {Piscataway, NJ},
 urldate = {2017-08-16},
 publisher = {IEEE},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE International Conference on Automatic Face {\&} Gesture Recognition} and FG}
}


@book{JamesJ.KuchandThomasS.Huang.1995,
 author = {{James J. Kuch and Thomas S. Huang}},
 year = {1995},
 title = {Vision Based Hand Modeling and Tracking for Virtual Teleconferencing and Telecollaboation: Fifth International Conference on Computer Vision, June 20-23, 1995, Massachusetts Institute of Technology, Cambridge, Massachusetts},
 keywords = {Computer vision;Congresses},
 address = {Los Alamitos, Calif},
 urldate = {2017-09-07},
 publisher = {{IEEE Computer Society Press}},
 institution = {{International Conference on Computer Vision} and {IEEE Computer Society}}
}


@article{Kim.2015,
 author = {Kim, Kwangtaek and Kim, Joongrock and Choi, Jaesung and Kim, Junghyun and Lee, Sangyoun},
 year = {2015},
 title = {Depth camera-based 3D hand gesture controls with immersive tactile feedback for natural mid-air gesture interactions},
 pages = {1022--1046},
 pagination = {page},
 volume = {15},
 number = {1},
 journal = {Sensors}
}


@book{Korein.1985,
 author = {Korein, James Urey},
 year = {1985},
 title = {A geometric investigation of reach: Zugl.: Pennsylvania Univ., Diss. : 1984},
 keywords = {11030;20020;21030;31030;anthropometric aspects;industrial;kinematics;Links and link-motion;Machinery, Kinematics of;manipulators;p1030;Robotics;robots},
 address = {Cambridge, Mass.},
 publisher = {{MIT Press}},
 isbn = {0262111047},
 series = {ACM distinguished dissertations}
}


@inproceedings{LaGorce.2008,
 abstract = {A novel model-based approach to 3D hand tracking from monocular video is presented. The 3D hand pose, the hand texture and the illuminant are dynamically estimated through minimization of an objective function. Derived from an inverse problem formulation, the objective function enables explicit use oftexture temporal continuity and shading information, while handling important self-occlusions and time-varying illumination. The minimization is done efficiently using a quasi-Newton method, for which we propose a rigorous derivation of the objective function gradient. Particular attention is given to terms related to the change of visibility near self-occlusion boundaries that are neglected in existing formulations. In doing so we introduce new occlusion forces and show that using all gradient terms greatly improves the performance of the method. Experimental results demonstrate the potential ofthe formulation.},
 author = {de {La Gorce}, Martin and Paragios, Nikos and Fleet, David J.},
 title = {Model-based hand tracking with texture, shading and self-occlusions},
 pages = {1--8},
 bookpagination = {page},
 publisher = {{IEEE Service Center}},
 isbn = {978-1-4244-2242-5},
 booktitle = {IEEE Conference on Computer Vision and Pattern Recognition, 2008},
 year = {2008},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPR.2008.4587752}
}


@article{Lee.1995,
 author = {Lee, Jintae and Kunii, T. L.},
 year = {1995},
 title = {Model-based analysis of hand posture},
 pages = {77--86},
 pagination = {page},
 volume = {15},
 number = {5},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/38.403831}
}


@article{Lepetit.2005,
 author = {Lepetit, Vincent and Fua, Pascal},
 year = {2005},
 title = {Monocular Model-Based 3D Tracking of Rigid Objects: A Survey},
 pages = {1--89},
 pagination = {page},
 volume = {1},
 number = {1},
 issn = {1572-2740},
 journal = {Foundations and Trends{\circledR} in Computer Graphics and Vision},
 doi = {10.1561/0600000001}
}


@inproceedings{Li.2009,
 author = {Li, Jituo and Bai, Li and Wang, Yangsheng and Tosas, Martin},
 title = {Hand tracking and animation},
 pages = {318--323},
 bookpagination = {page},
 booktitle = {Computer-Aided Design and Computer Graphics, 2009. CAD/Graphics' 09. 11th IEEE International Conference on},
 year = {2009}
}


@article{Lien.1998,
 abstract = {Conventional model-based hand gesture analysis systems require high computation cost to solve the finger inverse kinematics that makes them very difficult for real-time implementation. In this paper, we propose a fast hand model fitting method for the tracking of hand motion. The model fitting method consists of (1) finding the closed-form inverse kinematics solution for the finger fitting process, and (2) defining the alignment measure for the wrist fitting process. In the experiments, we illustrate that our hand model fitting method is effective and real-time implementable.},
 author = {Lien, Cheng-Chang and Huang, Chung-Lin},
 year = {1998},
 title = {Model-based articulated hand motion tracking for gesture recognition},
 keywords = {Finger inverse Kinematics;Gesture Recognition;Model based techniques;Realtime implementable hand motion tracking},
 pages = {121--134},
 pagination = {page},
 volume = {16},
 number = {2},
 journal = {Image and Vision Computing},
 doi = {10.1016/S0262-8856(97)00041-3}
}


@inproceedings{Lin.2000,
 abstract = {Hand motion capturing is one of the most important parts of gesture interfaces. Many current approaches to this task generally involve a formidable nonlinear optimization problem in a large search space. Motion capturing can be achieved more cost-efficiently when considering the motion constraints of a hand. Although some constraints can be represented as equalities or inequalities, there exist many constraints, which cannot be explicitly represented. In this paper, we propose a learning approach to model the hand configuration space directly. The redundancy of the configuration space can be eliminated by finding a lower-dimensional subspace of the original space. Finger motion is modeled in this subspace based on the linear behavior observed in the real motion data collected by a CyberGlove. Employing the constrained motion model, we are able to efficiently capture finger motion from video inputs. Several experiments show that our proposed model is helpful for capturing articulated motion.},
 author = {Lin, John and Wu, Ying and Huang, T. S.},
 title = {Modeling the constraints of human hand motion},
 pages = {121--126},
 bookpagination = {page},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0939-8},
 booktitle = {Proceedings, Workshop on Human Motion},
 year = {2000},
 address = {Los Alamitos, Calif},
 doi = {10.1109/HUMO.2000.897381}
}


@article{Lucas.2016,
 abstract = {TeX output 2000.10.11:1429},
 author = {Lucas, Stuart R. and Tischler, Craig R. and Samuel, Andrew E.},
 year = {2016},
 title = {Real-Time Solution of the Inverse Kinematic-Rate Problem},
 urldate = {2017-09-22},
 pages = {1236--1244},
 pagination = {page},
 volume = {19},
 number = {12},
 issn = {0278-3649},
 journal = {The International Journal of Robotics Research},
 doi = {10.1177/02783640022068057}
}


@inproceedings{MacCormick.2000,
 author = {MacCormick, John and Isard, Michael},
 title = {Partitioned sampling, articulated objects, and interface-quality hand tracking},
 pages = {3--19},
 bookpagination = {page},
 booktitle = {European Conference on Computer Vision},
 year = {2000}
}


@inproceedings{Mauthner.2008,
 author = {Mauthner, Thomas and Donoser, Michael and Bischof, Horst},
 title = {Robust tracking of spatial related components},
 pages = {1--4},
 bookpagination = {page},
 booktitle = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
 year = {2008}
}


@article{ModMaasum.2015,
 abstract = {Hand gesture recognition system has evolved tremendously in the recent few years because of its ability to interact with machine efficiently. Mankind tries to incorporate human gestures into modern technology by searching and finding a replacement of multi touch technology which does not require any touching movement on screen. This paper presents an overview on several methods to realize hand gesture recognition by using three main modules: camera and segmentation module, detection module and feature extraction module. There are many methods which can be used to get the respective results depending on its advantages. Summary of previous research and results of hand gesture methods as well as comparison between gesture recognition are also given in this paper.},
 author = {{Mod Ma'asum}, Farah Farhana and Sulaiman, Suhana and Saparon, Azilah},
 year = {2015},
 title = {An Overview of Hand Gestures Recognition System Techniques},
 pages = {012012},
 pagination = {page},
 volume = {99},
 issn = {1757-8981},
 journal = {IOP Conference Series: Materials Science and Engineering},
 doi = {10.1088/1757-899X/99/1/012012}
}


@article{Orin.1984,
 abstract = {This paper discusses and compares six different methods for calculating the Jacobian for a manipulator. We enumerate the computational efficiency of each in terms general N- degree-of-freedom of the total number of multiplications, addiof the number of matrix-vector operations

tions/subtractions, and trigonometric functions required as well as in terms

needed. We also give the execution times on a

minicomputer for determining the Jacobian for an

of the best new

PDP-11/70 example seven-degree-of-freedom manipulator. This paper formulates one

methods for determining the Jacobian.},
 author = {Orin, David E. and Schrader, William W.},
 year = {1984},
 title = {Efficient Computation of the Jacobian for Robot Manipulators},
 urldate = {2017-09-22},
 volume = {Vol.3},
 number = {No.4},
 issn = {0278-3649},
 journal = {The International Journal of Robotics Research}
}


@inproceedings{Pan.2017,
 author = {Pan, Matthew KXJ and Niemeyer, G{\"u}nter},
 title = {Catching a real ball in virtual reality},
 pages = {269--270},
 bookpagination = {page},
 booktitle = {Virtual Reality (VR), 2017 IEEE},
 year = {2017}
}


@article{PaulJ.BeslNeilD.McKay.1992,
 author = {{Paul J. Besl, Neil D.McKay}},
 year = {1992},
 title = {A method for registration of 3-D shapes - Pattern Analysis and Machine Intelligence,},
 keywords = {3D Object registration Overview of registration methods in early years},
 urldate = {2017-08-17},
 journal = {IEEE transactions on pattern analysis and machine intelligence}
}


@article{Penrose.1956,
 abstract = {Mathematical Proceedings of the Cambridge Philosophical Society},
 author = {Penrose, R. and Todd, J. A.},
 year = {1956},
 title = {On best approximate solutions of linear matrix equations},
 urldate = {2017-09-22},
 pages = {17},
 pagination = {page},
 volume = {52},
 number = {01},
 issn = {0305-0041},
 journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
 doi = {10.1017/S0305004100030929}
}


@inproceedings{Prisacariu.2011,
 author = {Prisacariu, Victor Adrian and Reid, Ian},
 title = {Robust 3D hand tracking for human computer interaction},
 pages = {368--375},
 bookpagination = {page},
 booktitle = {Automatic Face {\&} Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
 year = {2011}
}


@inproceedings{Qian.2014,
 author = {Qian, Chen and Sun, Xiao and Wei, Yichen and Tang, Xiaoou and Sun, Jian},
 title = {Realtime and robust hand tracking from depth},
 pages = {1106--1113},
 bookpagination = {page},
 booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
 year = {2014}
}


@inproceedings{Rehg.1994,
 author = {Rehg, James M. and Kanade, Takeo},
 title = {Visual tracking of high dof articulated structures: An application to human hand tracking},
 pages = {35--46},
 bookpagination = {page},
 booktitle = {European conference on computer vision},
 year = {1994}
}


@inproceedings{Rijpkema.1991,
 author = {Rijpkema, Hans and Girard, Michael},
 title = {Computer animation of knowledge-based human grasping},
 urldate = {2017-09-15},
 pages = {339--348},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {0897914368},
 editor = {Thomas, James J.},
 booktitle = {Proceedings of the 18th annual conference on Computer graphics and interactive techniques},
 year = {1991},
 address = {New York, NY},
 doi = {10.1145/122718.122754}
}


@article{RUDRAPKPOUDEL.2014,
 author = {{RUDRA P K POUDEL}},
 year = {2014},
 title = {3D Hand Tracking: A thesis submitted in partial fulfilment of the requirements of Bournemouth University for the degree of Doctor of Philosophy},
 urldate = {2017-08-17}
}


@article{Sangineto.2012,
 abstract = {Over the past few years there has been a growing interest in visual interfaces based on gestures. Using

gestures as a mean to communicate with a computer can be helpful in applications such as gaming platforms,

domotic environments, augmented reality or sign language interpretation to name a few. However, a serious

bottleneck for such interfaces is the current lack of accurate hand localization systems, which are necessary

for tracking (re-)initialization and hand pose understanding. In fact, human hand is an articulated object with

a very large degree of appearance variability which is difficult to deal with. For instance, recent attempts to

solve this problem using machine learning approaches have shown poor generalization capabilities over

different viewpoints and finger spatial configurations.

In this article we present a model based approach to articulated hand detection which splits this variability

problem by separately searching for simple finger models in the input image. A generic finger silhouette is

localized in the edge map of the input image by combining curve and graph matching techniques. Cluttered

backgrounds and thick textured images, which usually make it hard to compare edge information with

silhouette models (e.g., using chamfer distance or voting based methods) are dealt with in our approach

by simultaneously using connected curves and topological information. Finally, detected fingers are clustered

using geometric constraints. Our system is able to localize in real time a hand with variable finger configurations

in images with complex backgrounds, different lighting conditions and different positions of the hand

with respect to the camera. Experiments with real images and videos and a simple visual interface are

presented to validate the proposed method.},
 author = {Sangineto, Enver and Cupelli, Marco},
 year = {2012},
 title = {Real-time viewpoint-invariant hand localization with cluttered backgrounds},
 keywords = {Articulated object recognition;Curve matching;Geometric constraints;Graph matching;Hand detection;Model based techniques},
 pages = {26--37},
 pagination = {page},
 volume = {30},
 number = {1},
 journal = {Image and Vision Computing}
}


@article{Shan.2007,
 author = {Shan, Caifeng and Tan, Tieniu and Wei, Yucheng},
 year = {2007},
 title = {Real-time hand tracking using a mean shift embedded particle filter},
 pages = {1958--1970},
 pagination = {page},
 volume = {40},
 number = {7},
 journal = {Pattern recognition}
}


@proceedings{Springer.1994,
 year = {1994},
 title = {European conference on computer vision},
 institution = {Springer}
}


@proceedings{Springer.2000,
 year = {2000},
 title = {European Conference on Computer Vision},
 institution = {Springer}
}


@article{SrinathSridharAnttiOulasvirtaChristianTheobalt.2014,
 abstract = {Using hand gestures as input in human--computer interaction is of everincreasing interest. Markerless tracking of hands and fingers is a promising enabler, but adoption has been hampered because of tracking problems, complex and dense capture setups, high computing requirements, equipment costs, and poor latency. In this paper, we present a method that addresses these issues. Our method tracks rapid and complex articulations of the hand using a single depth camera. It is fast (50 fps without GPU support) and supports varying close-range camera-to-scene arrangements, such as in desktop or egocentric settings, where the camera can even move. We frame pose estimation as an optimization problem in depth using a new objective function based on a collection of Gaussian functions, focusing particularly on robust tracking of finger articulations. We demonstrate the benefits of the method in several interaction applications ranging from manipulating objects in a 3D blocks world to egocentric interaction on the go. We also present extensive evaluation of our method on publicly available datasets which shows that our method achieves competitive accuracy.},
 author = {{Srinath Sridhar, Antti Oulasvirta, Christian Theobalt}},
 year = {2014},
 title = {Fast Tracking of Hand and Finger Articulations Using a Single Depth Camera},
 keywords = {3D Interaction;Hand tracking;realtime Tracking},
 urldate = {2017-08-17}
}


@article{Stenger.,
 abstract = {This paper presents a practical technique for modelbased 3D hand tracking. An anatomically accurate hand model is built from truncated quadrics. This allows for the generation of2D profiles ofthe model using elegant tools from projective geometry, and for an efficient method to handle self-occlusion. The pose ofthe hand model is estimated with an Unscented Kalman filter (UKF), which minimizes the geometric error between the profiles andedges extracted from the images. The use ofthe UKF permits higher frame rates than more sophisticated estimation methods such as particle filtering, whilst providing higher accuracy than the extended Kalman filter. The system is easily scalable from single to multiple views, and from rigid to articulated models. First experiments on real data using one and two cameras demonstrate the quality of the proposed method for tracking a 7 DOF hand model.},
 author = {Stenger and Mendoca and Cipolla},
 title = {Model-Based 3D Tracking of an Articulated Hand},
 urldate = {2017-08-25}
}


@inproceedings{Stenger.2001,
 abstract = {This paper presents a novel method for hand tracking. It uses a 3D model built from quadrics which approximates the anatomy of a human hand. This approach allows for the use of results from projective geometry that yield an elegant technique to generate the projection ofthe model as a set ofconics, as well as providing an efficient ray tracing algorithm to handle self-occlusion. Once the model is projected, an Unscented Kalman Filter is used to update its pose in order to minimise the geometric error between the model projection and a video sequence on the background. Results from experiments with real data show the accuracy of the technique.},
 author = {Stenger, Bjoern and Mendon{\c{c}}a, Paulo R. S. and Cipolla, Roberto},
 title = {Model-Based Hand Tracking Using an Unscented Kalman Filter},
 pages = {63--72},
 bookpagination = {page},
 volume = {1},
 booktitle = {BMVC},
 year = {2001}
}


@article{Stenger.2006,
 abstract = {This thesis focuses on the automatic recovery of three-dimensional hand motion from one or more views. A 3D geometric hand model is constructed from truncated cones, cylinders and ellipsoids and is used to generate contours, which can be compared with edge contours and skin colour in images. The hand tracking problem is formulated as state estimation, where the model parameters define the internal state, which is to be estimated from image observations.

In the first approach, an unscented Kalman filter is employed to update the model's pose based on local intensity or skin colour edges. The algorithm is able to track smooth hand motion in front of backgrounds that are either uniform or contain no skin colour. However, manual initialization is required in the first frame, and no recovery strategy is available when track is lost.

The second approach, tree-based filtering, combines ideas from detection and Bayesian filtering: Detection is used to solve the initialization problem, where a single image is given with no prior information of the hand pose. A hierarchical Bayesian filter is developed, which allows integration of temporal information. This is more efficient than applying detection at each frame, because dynamic information can be incorporated into the search, which helps to resolve ambiguities in difficult cases. This thesis develops a likelihood function, which is based on intensity edges, as well as pixel colour values. This function is obtained from a similarity measure, which is compared with a number of other cost functions. The posterior distribution is computed in a hierarchical fashion, the aim being to concentrate computation power on regions in state space with larger posterior values. The algorithm is tested on a number of image sequences, which include hand motion with self-occlusion in front of a cluttered background.},
 author = {Stenger, Bj{\"o}rn and Thayananthan, Arasanathan and Torr, Philip H. S. and Cipolla, Roberto},
 year = {2006},
 title = {Model-based hand tracking using a hierarchical bayesian filter},
 pages = {1372--1384},
 pagination = {page},
 volume = {28},
 number = {9},
 journal = {IEEE transactions on pattern analysis and machine intelligence}
}


@article{Sturman.1994,
 author = {Sturman, D. J. and Zeltzer, D.},
 year = {1994},
 title = {A survey of glove-based input},
 pages = {30--39},
 pagination = {page},
 volume = {14},
 number = {1},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/38.250916}
}


@inproceedings{Sun.2009,
 author = {Sun, Li and Klank, Ulrich and Beetz, Michael},
 title = {EYEWATCHME---3D hand and object tracking for inside out activity analysis},
 pages = {9--16},
 bookpagination = {page},
 booktitle = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
 year = {2009}
}


@inproceedings{Sun.2011,
 author = {Sun, Li and Liu, Guizhong},
 title = {Hand tracking based on the combination of 2D and 3D model in gaze-directed video},
 pages = {1--6},
 bookpagination = {page},
 booktitle = {Multimedia and Expo (ICME), 2011 IEEE International Conference on},
 year = {2011}
}


@proceedings{Thomas.1991,
 year = {1991},
 title = {Proceedings of the 18th annual conference on Computer graphics and interactive techniques},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {0897914368},
 editor = {Thomas, James J.},
 institution = {{ACM Special Interest Group on Computer Graphics and Interactive Techniques}},
 doi = {10.1145/122718}
}


@proceedings{Tollmar.2008,
 year = {2008},
 title = {Proceedings of the 5th Nordic conference on Human-computer interaction building bridges},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {9781595937049},
 editor = {Tollmar, Konrad},
 doi = {10.1145/1463160}
}


@article{Wan.2014,
 author = {Wan, Jun and Ruan, Qiuqi and An, Gaoyun and Li, Wei and Liang, Yanyan and Zhao, Ruizhen},
 year = {2014},
 title = {The dynamic model embed in augmented graph cuts for robust hand tracking and segmentation in videos},
 volume = {2014},
 journal = {Mathematical Problems in Engineering}
}


@article{Wang.1991,
 author = {Wang, L.-C.T. and Chen, C. C.},
 year = {1991},
 title = {A combined optimization method for solving the inverse kinematics problems of mechanical manipulators},
 urldate = {2017-09-22},
 pages = {489--499},
 pagination = {page},
 volume = {7},
 number = {4},
 journal = {IEEE Transactions on Robotics and Automation},
 doi = {10.1109/70.86079}
}


@inproceedings{Wang.2009,
 author = {Wang, Robert Y. and Popovi{\'c}, Jovan},
 title = {Real-time hand-tracking with a color glove},
 pages = {63},
 bookpagination = {page},
 volume = {28},
 booktitle = {ACM transactions on graphics (TOG)},
 year = {2009}
}


@article{WayneWesterman.1999,
 author = {{Wayne Westerman}},
 year = {1999},
 title = {HAND TRACKING, FINGER IDENTIFICATION, AND CHORDIC MANIPULATION ON A MULTI-TOUCH SURFACE: A dissertation submitted to the Faculty of the University of Delaware in partial fulllment of the requirements for the degree of Doctor of Philosophy in Electrical Engineering},
 urldate = {2017-08-16}
}


@inproceedings{Weerasekera.2013,
 author = {Weerasekera, C. S. and Jaward, Mohamed Hisham and Kamrani, Nader},
 title = {Robust asl fingerspelling recognition using local binary patterns and geometric features},
 pages = {1--8},
 bookpagination = {page},
 booktitle = {Digital Image Computing: Techniques and Applications (DICTA), 2013 International Conference on},
 year = {2013}
}


@article{Welman.,
 abstract = {Computer animation; Computer graphics; Kinematics -- Computer simulation.},
 author = {Welman, Chris.},
 title = {Inverse kinematics and geometric constraints for articulated figure manipulation},
 urldate = {2017-09-14}
}


@inproceedings{Wolovich.1984,
 author = {Wolovich, W. and Elliott, H.},
 title = {A computational technique for inverse kinematics},
 pages = {1359--1363},
 bookpagination = {page},
 publisher = {IEEE},
 booktitle = {The 23rd IEEE Conference on Decision and Control},
 year = {1984},
 doi = {10.1109/CDC.1984.272258}
}


@proceedings{WorkshoponHumanMotion.2000,
 year = {2000},
 title = {Proceedings, Workshop on Human Motion: 7-8 December 2000, Austin, Texas},
 price = {microfiche},
 keywords = {Automation;Computer simulation;Computer vision;Congresses;Data processing;Face perception;Gesture;Human locomotion;Kinesiology;Optical pattern recognition},
 address = {Los Alamitos, Calif},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0939-8},
 institution = {{Workshop on Human Motion} and {IEEE Computer Society}}
}


@article{Zhang.2015,
 abstract = {Neurocomputing, 157 + (2015) 296-305. doi:10.1016/j.neucom.2015.01.002},
 author = {Zhang, Xiaoqin and Li, Wei and Ye, Xiuzi and Maybank, Stephen},
 year = {2015},
 title = {Robust hand tracking via novel multi-cue integration},
 keywords = {Feature selection;Hand tracking;Multi-cue integration;RCD},
 urldate = {2017-08-16},
 pages = {296--305},
 pagination = {page},
 volume = {157},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2015.01.002}
}


@article{Zhang.2015b,
 author = {Zhang, Xiaoqin and Li, Wei and Ye, Xiuzi and Maybank, Stephen},
 year = {2015},
 title = {Robust hand tracking via novel multi-cue integration},
 pages = {296--305},
 pagination = {page},
 volume = {157},
 journal = {Neurocomputing}
}


@article{Zhao.1994,
 author = {Zhao, Jianmin and Badler, Norman I.},
 year = {1994},
 title = {Inverse kinematics positioning using nonlinear programming for highly articulated figures},
 urldate = {2017-09-22},
 pages = {313--336},
 pagination = {page},
 volume = {13},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/195826.195827}
}


@article{Zhao.1994b,
 abstract = {An articulated figure is often modeled as a set of rigid segments connected with joints. Its configuration can be altered by varying the joint angles. Although it is straightforward to compute figure configurations given joint angles (forward kinematics), it is more difficult to find the joint angles for a desired configuration (inverse kinematics). Since the inverse kinematics problem is of special importance to an animator wishing to set a figure to a posture satisfying a set of positioning constraints, researchers have proposed several different approaches. However, when we try to follow these approaches in an interactive animation system where the object on which LOoperate is as highly articulated as a realistic human figure, they fail in either generality or performance. So, we approach this problem through nonlinear programming techniques. It has been successfully used since 1988 in the spatial constraint system within Jack {\grq}W,a human figure simulation system developed at the University of Pennsylvania, and proves to be satisfactorily eff]cient, controllable, and robust. A spatial constraint in our system involves two parts: one constraint on the figure, the end-eflector, and one on the spatial environment, the goal. These two parts are dealt with separately, so that wc can achieve a neat modular implementation. Constraints can be added one at a time with appropriate weights designating the importance of this constraint relative to the others and are always solved as a group. [f physical limits prevent satisfaction of all the constraints, the system stops with the (possibly local) optimal solution for the given weights. Also, the rigidity of each joint angle can be controlled, which is useful for redundant degrees of freedom.},
 author = {Zhao, Jianmin and Badler, Norman I.},
 year = {1994},
 title = {Inverse kinematics positioning using nonlinear programming for highly articulated figures},
 urldate = {2017-09-22},
 pages = {313--336},
 pagination = {page},
 volume = {13},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/195826.195827}
}


@article{Zhao.1994c,
 abstract = {An articulated figure is often modeled as a set of rigid segments connected with joints. Its configuration can be altered by varying the joint angles. Although it is straightforward to compute figure configurations given joint angles (forward kinematics), it is more difficult to find the joint angles for a desired configuration (inverse kinematics). Since the inverse kinematics problem is of special importance to an animator wishing to set a figure to a posture satisfying a set of positioning constraints, researchers have proposed several different approaches. However, when we try to follow these approaches in an interactive animation system where the object on which LOoperate is as highly articulated as a realistic human figure, they fail in either generality or performance. So, we approach this problem through nonlinear programming techniques. It has been successfully used since 1988 in the spatial constraint system within Jack {\grq}W,a human figure simulation system developed at the University of Pennsylvania, and proves to be satisfactorily eff]cient, controllable, and robust. A spatial constraint in our system involves two parts: one constraint on the figure, the end-eflector, and one on the spatial environment, the goal. These two parts are dealt with separately, so that wc can achieve a neat modular implementation. Constraints can be added one at a time with appropriate weights designating the importance of this constraint relative to the others and are always solved as a group. [f physical limits prevent satisfaction of all the constraints, the system stops with the (possibly local) optimal solution for the given weights. Also, the rigidity of each joint angle can be controlled, which is useful for redundant degrees of freedom.},
 author = {Zhao, Jianmin and Badler, Norman I.},
 year = {1994},
 title = {Inverse kinematics positioning using nonlinear programming for highly articulated figures},
 urldate = {2017-09-22},
 pages = {313--336},
 pagination = {page},
 volume = {13},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/195826.195827}
}


