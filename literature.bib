% This file was created with Citavi 5.7.1.0

@article{.,
 author = {{Taehee Lee} and H{\"o}llerer},
 title = {Handy AR: Markerless Inspection of Augmented Reality Objects Using Fingertip Tracking},
 urldate = {2018-01-17}
}


@proceedings{.1984,
 year = {1984},
 title = {The 23rd IEEE Conference on Decision and Control},
 publisher = {IEEE}
}


@book{.1998,
 year = {1998},
 title = {Automatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference on},
 isbn = {9780818683442}
}


@book{.1998b,
 year = {1998},
 title = {Proceedings},
 keywords = {Gestes;Interaction homme-machine (Informatique);Perception des visages;Reconnaissance optique des formes (Informatique);Traitement d'images},
 address = {[Piscataway, NJ]},
 publisher = {IEEE}
}


@book{.1998c,
 year = {1998},
 title = {Third IEEE International Conference on Automatic Face and Gesture Recognition, 1998. Proceedings},
 publisher = {{IEEE / Institute of Electrical and Electronics Engineers Incorporated}}
}


@proceedings{.2001,
 year = {2001},
 title = {BMVC}
}


@book{.2002c1998,
 year = {2002, c1998},
 title = {Third IEEE International Conference on Automatic Face and Gesture Recognition: Proceedings : April 14-16, 1998, Nara, Japan},
 keywords = {Extraction des primitives;Reconnaissance des gestes;Reconnaissance faciale},
 address = {Los Alamitos, Calif.},
 publisher = {{IEEE Computer Society}}
}


@proceedings{.2004,
 year = {2004},
 title = {Proc. of 5th Intl Conf. Disability, Virtual Reality Assoc. Tech., Oxford, UK}
}


@proceedings{.2007,
 year = {2007},
 title = {Proceedings of the Workshop at the IEEE Virtual Reality 2007 Conference; Trends and Issues in Tracking for Virtual Environments}
}


@proceedings{.2014,
 year = {2014},
 title = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}


@misc{.d,
 abstract = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they},
 title = {Snakes: Active contour models},
 url = {https://link.springer.com/article/10.1007%2FBF00133570?LI=true},
 urldate = {2017-08-17}
}


@article{A.Balestrino.1984,
 author = {{A. Balestrino} and {G. De Maria} and {L. Sciavicco}},
 year = {1984},
 title = {Robust Control of Robotic Manipulators},
 pages = {2435--2440},
 pagination = {page},
 volume = {17},
 number = {2},
 issn = {1474-6670},
 journal = {IFAC Proceedings Volumes},
 doi = {10.1016/S1474-6670(17)61347-8}
}


@proceedings{ACM.2009,
 year = {2009},
 title = {ACM transactions on graphics (TOG)},
 institution = {ACM}
}


@article{Alemzadeh.,
 author = {Alemzadeh, Milad},
 title = {Human-Computer Interaction: An Overview},
 urldate = {2017-08-17}
}


@article{AndreasAristidouandJoanLasenby.2009,
 author = {{Andreas Aristidou and Joan Lasenby}},
 year = {2009},
 title = {Inverse Kinematics: a review of existing techniques and introduction of a new fast iterative solver: University of Cambridge, Department of Engineering},
 keywords = {Inverse Kinematics FABRIK Joint configuration CCD Jacobian Inverse},
 urldate = {2017-09-14}
}


@misc{AntonioTorralbaKevinP.MurphyandWilliamT.Freeman.,
 abstract = {We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery},
 author = {{Antonio Torralba, Kevin P. Murphy and William T. Freeman}},
 title = {Sharing Visual Features for Multiclass and Multiview Object Detection - IEEE Xplore Document},
 url = {http://ieeexplore.ieee.org/abstract/document/4135679/},
 urldate = {2017-08-13}
}


@proceedings{Appolloni.2002,
 year = {2002},
 title = {ACM SIGGRAPH 2002 conference abstracts and applications},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {1581135254},
 editor = {Appolloni, Tom},
 institution = {{ACM Special Interest Group on Computer Graphics and Interactive Techniques}},
 doi = {10.1145/1242073}
}


@inproceedings{Aristidou.2010,
 author = {Aristidou, Andreas and Lasenby, Joan},
 title = {Motion capture with constrained inverse kinematics for real-time hand tracking},
 keywords = {Augmented reality;Hand tracking;motion capture;User Interface},
 pages = {1--5},
 bookpagination = {page},
 booktitle = {Communications, Control and Signal Processing (ISCCSP), 2010 4th International Symposium on},
 year = {2010}
}


@article{Aristidou.2011,
 abstract = {GRAPHICAL MODELS, 73 (2011) 243-260. doi:10.1016/j.gmod.2011.05.003},
 author = {Aristidou, Andreas and Lasenby, Joan},
 year = {2011},
 title = {FABRIK: A fast, iterative solver for the Inverse Kinematics problem},
 keywords = {Human animation;Inverse Kinematics;Joint configuration;Motion reconstruction},
 urldate = {2017-09-14},
 pages = {243--260},
 pagination = {page},
 volume = {73},
 number = {5},
 issn = {15240703},
 journal = {Graphical Models},
 doi = {10.1016/j.gmod.2011.05.003}
}


@article{Aristidou.2013,
 abstract = {Optical motion capture systems suffer from marker

occlusions resulting in loss of useful information. This

paper addresses the problem of real-time joint localisation

of legged skeletons in the presence of such missing data.

The data is assumed to be labelled 3d marker positions from

a motion capture system. An integrated framework is presented

which predicts the occluded marker positions using

a Variable Turn Model within an Unscented Kalman filter.

Inferred information from neighbouring markers is used

as observation states; these constraints are efficient, simple,

and real-time implementable. This work also takes advantage

of the common case that missing markers are still

visible to a single camera, by combining predictions with

under-determined positions, resulting in more accurate predictions.

An Inverse Kinematics technique is then applied

ensuring that the bone lengths remain constant over time;

the system can thereby maintain a continuous data-flow. The

marker and Centre of Rotation (CoR) positions can be calculated

with high accuracy even in cases where markers

are occluded for a long period of time. Our methodology is

tested against some of the most popular methods for marker

prediction and the results confirm that our approach outperforms

these methods in estimating both marker and CoR positions.},
 author = {Aristidou, Andreas and Lasenby, Joan},
 year = {2013},
 title = {Real-time marker prediction and CoR estimation in optical motion capture},
 urldate = {2017-08-25},
 pages = {7--26},
 pagination = {page},
 volume = {29},
 number = {1},
 issn = {0178-2789},
 journal = {The Visual Computer},
 doi = {10.1007/s00371-011-0671-y}
}


@article{Badler.1987,
 author = {Badler, Norman and Manoochehri, Kamran and Walters, Graham},
 year = {1987},
 title = {Articulated Figure Positioning by Multiple Constraints},
 keywords = {Constraints},
 urldate = {2017-09-15},
 pages = {28--38},
 pagination = {page},
 volume = {7},
 number = {6},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/MCG.1987.276894}
}


@article{Besl.1988,
 author = {Besl, P. J.},
 year = {1988},
 title = {Geometric modeling and computer vision},
 urldate = {2017-08-17},
 pages = {936--958},
 pagination = {page},
 volume = {76},
 number = {8},
 issn = {00189219},
 journal = {Proceedings of the IEEE},
 doi = {10.1109/5.5966}
}


@inproceedings{Bolt.1980,
 author = {Bolt, Richard A.},
 title = {Put-that-there},
 pages = {262--270},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {0897910214},
 editor = {Thomas, James J.},
 booktitle = {Proceedings of the 7th annual conference on Computer graphics and interactive techniques},
 year = {1980},
 address = {New York, NY},
 doi = {10.1145/800250.807503}
}


@article{CarloColombo.,
 abstract = {We present a nonintrusive system based on computer vision for human-computer interaction in three--dimensional (3-D) environments controlled by hand pointing gestures. Users are allowed to walk around in a room and manipulate information displayed on its walls by using their own hands as pointing devices. Once captured and tracked in real-time using stereo vision, hand pointing gestures are remapped onto the current point of interest, thus reproducing in an advanced interaction scenario the ``drag and click'' behavior of traditional mice. The system, called PointAt (patent pending), enjoys a careful modeling of both user and optical subsystem, and visual algorithms for self-calibration and adaptation to both user peculiarities and environmental changes. The concluding sections provide an insight into system characteristics, performance, and relevance for real applications.},
 author = {{Carlo Colombo} and {Alberto Del Bimbo} and {and Alessandro Valli}},
 year = {2003},
 title = {Visual capture and understanding of hand pointing actions in a 3-D environment},
 url = {http://ieeexplore.ieee.org/abstract/document/1213560/},
 urldate = {2017-08-13},
 volume = {33},
 number = {4}
}


@misc{Chaudhary.20130310,
 author = {Chaudhary, Ankit and Raheja, J. L. and Das, Karen and Raheja, Sonia},
 year = {2013},
 title = {Intelligent Approaches to interact with Machines using Hand Gesture Recognition in Natural way: A Survey},
 url = {http://arxiv.org/pdf/1303.2292}
}


@article{Chiaverini.1994,
 author = {Chiaverini, S. and Siciliano, B. and Egeland, O.},
 year = {1994},
 title = {Review of the damped least-squares inverse kinematics with experiments on an industrial robot manipulator},
 pages = {123--134},
 pagination = {page},
 volume = {2},
 number = {2},
 issn = {10636536},
 journal = {IEEE Transactions on Control Systems Technology},
 doi = {10.1109/87.294335}
}


@article{Cootes.1995,
 author = {Cootes, Timothy F. and Taylor, Christopher J. and Cooper, David H. and Graham, Jim},
 year = {1995},
 title = {Active shape models-their training and application},
 pages = {38--59},
 pagination = {page},
 volume = {61},
 number = {1},
 journal = {Computer vision and image understanding}
}


@incollection{Courty.2008,
 abstract = {In this paper we propose an original approach to solve the Inverse Kinematics problem. Our framework is based on Sequential Monte Carlo Methods and has the advantage to avoid the classical pitfalls of numerical inversion methods since only direct calculations are required. The resulting algorithm accepts arbitrary constraints and exhibits linear complexity with respect to the number of degrees of freedom. Hence, the proposed system is far more efficient for articulated figures with a high number of degrees of freedom.},
 author = {Courty, Nicolas and Arnaud, Elise},
 title = {Inverse Kinematics Using Sequential Monte Carlo Methods},
 pages = {1--10},
 bookpagination = {page},
 publisher = {Springer},
 isbn = {978-3-540-70517-8},
 series = {Lecture Notes in Computer Science},
 editor = {Hutchison, David and Fisher, Robert B. and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and {Pandu Rangan}, C. and Perales, Francisco Jos{\'e}},
 booktitle = {Articulated Motion and Deformable Objects},
 year = {2008},
 address = {Berlin and Heidelberg}
}


@proceedings{Cunningham.1998,
 year = {1998},
 title = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {0897919998},
 editor = {Cunningham, Steve},
 institution = {{ACM Special Interest Group on Computer Graphics and Interactive Techniques}},
 doi = {10.1145/280814}
}


@book{Dahmen.2008,
 author = {Dahmen, Wolfgang and Reusken, Arnold},
 year = {2008},
 title = {Numerik f{\"u}r Ingenieure und Naturwissenschaftler},
 url = {http://dx.doi.org/10.1007/978-3-540-76493-9},
 keywords = {Lehrbuch;Numerische Mathematik;Online-Publikation},
 address = {Berlin Heidelberg},
 edition = {Zweite, korrigierte Auflage},
 publisher = {{Springer-Verlag Berlin Heidelberg}},
 isbn = {9783540764939},
 series = {Springer-Lehrbuch}
}


@article{DavidE.Orin.1984,
 abstract = {This paper discusses and compares six different methods for calculating the Jacobian for a manipulator. We enumerate the computational efficiency of each in terms general N- degree-of-freedom of the total number of multiplications, addiof the number of matrix-vector operations

tions/subtractions, and trigonometric functions required as well as in terms

needed. We also give the execution times on a

minicomputer for determining the Jacobian for an

of the best new

PDP-11/70 example seven-degree-of-freedom manipulator. This paper formulates one

methods for determining the Jacobian.},
 author = {{David E. Orin} and {William W. Schrader}},
 year = {1984},
 title = {Efficient Computation of the Jacobian for Robot Manipulators},
 urldate = {2017-10-06},
 pages = {66--75},
 pagination = {page},
 volume = {3},
 number = {4},
 issn = {0278-3649},
 journal = {The International Journal of Robotics Research}
}


@article{Denavit.1955,
 author = {Denavit, Jacques},
 year = {1955},
 title = {A kinematic notation for lower-pair mechanisms based on matrices},
 pages = {215--221},
 pagination = {page},
 journal = {ASME J. Appl. Mech.}
}


@book{DesmondChik.2008,
 author = {{Desmond Chik} and {Jochen Trumpf} and {Nicol N. Schraudolph}},
 year = {2008},
 title = {Using an Adaptive VAR Model for Motion Prediction in 3D Hand Tracking: FG 2008 ; Amsterdam, Netherlands, 17 - 19 September 2008},
 keywords = {Gesicht;Mustererkennung},
 address = {Piscataway, NJ},
 urldate = {2017-08-16},
 publisher = {IEEE},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE International Conference on Automatic Face {\&} Gesture Recognition} and FG}
}


@article{Dipietro.2008,
 author = {Dipietro, L. and Sabatini, A. M. and Dario, P.},
 year = {2008},
 title = {A Survey of Glove-Based Systems and Their Applications},
 pages = {461--482},
 pagination = {page},
 volume = {38},
 number = {4},
 issn = {1094-6977},
 journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
 doi = {10.1109/TSMCC.2008.923862}
}


@inproceedings{Duca.2007,
 abstract = {The purpose of this project is to create a library that will allow its users to control 3D applications by using one or both of their hands. The final product could easily be incorporated into 3D applications, each customized to utilize a set of poses. Even though off-the-shelf motion capture gloves have reached lower prices in recent years, they are still expensive for home users. The algorithm suggested is based only on a single webcam combined with coded palm and fingers. Users should be able to code one or more of the fingers. One webcam is still somewhat constraining as two should ideally be used for 3D mapping of the hand, but by additionally using palm and finger coding we can greatly improve precision and, most importantly, reduce the processing power required for feasible real-time 3D interaction.},
 author = {Duca, Florin and Fredriksson, Jonas and Fjeld, Morten},
 title = {Real-time 3d hand interaction: Single webcam low-cost approach},
 pages = {1--5},
 bookpagination = {page},
 booktitle = {Proceedings of the Workshop at the IEEE Virtual Reality 2007 Conference; Trends and Issues in Tracking for Virtual Environments},
 year = {2007}
}


@article{ElSawah.2008,
 author = {El-Sawah, Ayman and Georganas, Nicolas D. and Petriu, Emil M.},
 year = {2008},
 title = {A prototype for 3-D hand tracking and posture estimation},
 pages = {1627--1636},
 pagination = {page},
 volume = {57},
 number = {8},
 journal = {IEEE Transactions on Instrumentation and Measurement}
}


@article{Erol.2007,
 author = {Erol, Ali and Bebis, George and Nicolescu, Mircea and Boyle, Richard D. and Twombly, Xander},
 year = {2007},
 title = {Vision-based hand pose estimation: A review},
 urldate = {2017-10-29},
 pages = {52--73},
 pagination = {page},
 volume = {108},
 number = {1-2},
 journal = {Computer vision and image understanding},
 doi = {10.1016/j.cviu.2006.10.012}
}


@article{FabienneLathuiIiere.2000,
 abstract = {v. 1. Computer vision and image analysis -- v. 2. Pattern recognition and neural networks -- v. 3. Image speech and signal processing -- v. 4. Applications robotics systems and architectures},
 author = {{Fabienne LathuiIiere} and {Jean-Yves Herve}},
 year = {2000},
 title = {Visual Tracking of Hand Posture with Occlusion Handling: Proceedings : Barcelona, Spain, September 3-7, 2000},
 keywords = {Computer vision;Congresses;Pattern recognition systems},
 urldate = {2017-10-29}
}


@article{Fanello.2014,
 author = {Fanello, Sean Ryan and Paek, Tim and Keskin, Cem and Izadi, Shahram and Kohli, Pushmeet and Kim, David and Sweeney, David and Criminisi, Antonio and Shotton, Jamie and Kang, Sing Bing},
 year = {2014},
 title = {Learning to be a depth camera for close-range human capture and interaction},
 keywords = {acquisition;depth camera;interaction;learning;learning, depth camera, acquisition, interaction},
 urldate = {2018-01-17},
 pages = {1--11},
 pagination = {page},
 volume = {33},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/2601097.2601223}
}


@book{FG.20,
 year = {20--},
 title = {3rd. International Conference on Face {\&} Gesture Recognition,Nara, Japan, 141998-04-16},
 address = {[S.l.]n[s.n.]},
 isbn = {9780818683442},
 institution = {FG}
}


@inproceedings{Foxlin.1998,
 author = {Foxlin, Eric and Harrington, Michael and Pfeifer, George},
 title = {Constellation},
 pages = {371--378},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {0897919998},
 editor = {Cunningham, Steve},
 booktitle = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
 year = {1998},
 address = {New York, NY},
 doi = {10.1145/280814.280937}
}


@inproceedings{Fredriksson.2008,
 abstract = {This paper presents a low-cost method for enabling 3D handcomputer interaction. The method, accompanied by a system, uses the frame capturing functionality of a single consumer-grade webcam. Our recent work has been focused on examining and realizing a less complex system. The presented method reduces the tracking effort to only one reference marker: a color-coded bracelet that helps locate the part of the captured frame containing the user's hand. The located area contains all the information needed to extract hand rotation and finger angle data. To facilitate hand feature extraction, we have outfitted the user's hand with a specially coded glove. The glove is equipped with two square palm markers, a marker on either side of the hand, and five distinctly shaded finger sheaths. We believe that an approach that only tracks only one marker will be more efficient than similar methods that track each finger separately. The method is further simplified by using spatial properties, drawn from physiological characteristics of the human hand, to limit the areas considered by the algorithm. Some challenges regarding webcam limitations may arise when attempting to carry this method into effect, including problems related to image noise and limited image- and color-resolution. Overlapping hands and fingers, hand positioning outside the field of view, and interference by local light sources are other exigent factors to consider.},
 author = {Fredriksson, Jonas and Ryen, Sven Berg and Fjeld, Morten},
 title = {Real-time 3D hand-computer interaction},
 keywords = {3D Hand-Computer Interaction;3D Interaction;3D Navigation;Gesture;Mixed Reality},
 pages = {133},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {9781595937049},
 editor = {Tollmar, Konrad},
 booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction building bridges},
 year = {2008},
 address = {New York, NY},
 doi = {10.1145/1463160.1463175}
}


@article{G.R.S.MurthyR.S.Jadon.JulyDecember2009,
 abstract = {{\th}ÿ},
 author = {{G. R. S. Murthy,R. S. Jadon}},
 year = {July-December 2009},
 title = {A REVIEW OF VISION BASED HAND GESTURES RECOGNITION},
 urldate = {2017-08-17},
 pages = {405--410},
 pagination = {page},
 number = {2},
 journal = {International Journal of Information Technology and Knowledge Management}
}


@article{Genc.,
 abstract = {ISMAR'02 Paper},
 author = {Genc, Yakup},
 title = {Marker-less Tracking for AR: A Learning-Based Approach},
 keywords = {Augmented reality;Marker-less Tracking;Marker-less Tracking, Augmented Reality},
 urldate = {2017-10-05}
}


@article{Golub.1965,
 author = {Golub, Gene and Kahan, William},
 year = {1965},
 title = {Calculating the singular values and pseudo-inverse of a matrix},
 url = {http://statistics.uchicago.edu/~lekheng/courses/302/classics/golub-kahan.pdf},
 urldate = {2017-10-06},
 pages = {205--224},
 pagination = {page},
 volume = {2},
 number = {2},
 journal = {ISAM}
}


@misc{Grimes.1983,
 author = {Grimes, Gary J.},
 year = {1983},
 title = {Digital data entry glove interface device},
 publisher = {{Google Patents}}
}


@article{Hartley.2000,
 author = {Hartley, Richard and Zisserman, Andrew},
 year = {2000},
 title = {Multiple View Geometry in Computer Vision Second Edition},
 journal = {Cambridge University Press}
}


@inproceedings{Henia.2011,
 author = {Henia, Ouissem Ben and Bouakaz, Saida},
 title = {3D Hand model animation with a new data-driven method},
 pages = {72--76},
 bookpagination = {page},
 booktitle = {Digital Media and Digital Content Management (DMDCM), 2011 Workshop on},
 year = {2011}
}


@inproceedings{HernandezRebollar.2002,
 author = {Hernandez-Rebollar, Jose L. and Kyriakopoulos, Nicholas and Lindeman, Robert W.},
 title = {The AcceleGlove},
 pages = {259},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {1581135254},
 editor = {Appolloni, Tom},
 booktitle = {ACM SIGGRAPH 2002 conference abstracts and applications},
 year = {2002},
 address = {New York, NY},
 doi = {10.1145/1242073.1242272}
}


@proceedings{HirokazuKato.1999,
 year = {1999},
 title = {Marker tracking and HMD calibration for a video-based augmentedreality conferencing system: October 20-21, 1999, San Francisco, California},
 price = {microfiche},
 keywords = {Computer graphics;Congresses;Virtual reality;Visualization},
 address = {Los Alamitos, Calif},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0359-4},
 editor = {{Hirokazu Kato} and {Mark Billinghurst}},
 institution = {{IEEE and ACM International Workshop on Augmented Reality} and {IEEE Computer Society}}
}


@book{Hutchison.2008,
 year = {2008},
 title = {Articulated Motion and Deformable Objects: 5th International Conference, AMDO 2008, Port d'Andratx, Mallorca, Spain, July 9-11, 2008. Proceedings},
 keywords = {Artificial intelligence;Automatische Sprachproduktion;Bewegungsanalyse;Computer graphics;Computer science;Computer simulation;Computer vision;Computeranimation;Deformierbares Objekt;Dreidimensionale Rekonstruktion;Erweiterte Realit{\"a}t;Mensch;Multimodales System;Objekterkennung;Optical pattern recognition;Szenenanalyse;Videobearbeitung},
 address = {Berlin and Heidelberg},
 volume = {5098},
 publisher = {Springer},
 isbn = {978-3-540-70517-8},
 series = {Lecture Notes in Computer Science},
 editor = {Hutchison, David and Fisher, Robert B. and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and {Pandu Rangan}, C. and Perales, Francisco Jos{\'e}},
 doi = {10.1007/978-3-540-70517-8}
}


@article{Huttenlocher.1993,
 author = {Huttenlocher, D. P. and Klanderman, G. A. and Rucklidge, W. J.},
 year = {1993},
 title = {Comparing images using the Hausdorff distance},
 pages = {850--863},
 pagination = {page},
 volume = {15},
 number = {9},
 issn = {01628828},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 doi = {10.1109/34.232073}
}


@book{IanBullock.2012,
 abstract = {Fourth IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics, June 24-27, 2012, Roma, Italy},
 author = {{Ian Bullock} and {Julia Borras Sol} and {Aaron Dollar}},
 year = {2012},
 title = {4th IEEE RAS {\&} EMBS International Conference on Biomedical Robotics and Biomechatronics (BioRob), 2012: 24 - 27 June 2012, Rome, Italy ; [including] the first edition of the Symposium on Surgical Robotics ; part of the Bioengineering Week (June 20 - 29, 2012)},
 keywords = {Biological systems modeling;Biomechatronic and human-centred design;Bionics;Congresses;ilmpub;Locomotion and manipulation in robots and biological systems;Mechatronics;Robotics;Robotics in medicine},
 address = {Piscataway, NJ},
 urldate = {2017-11-03},
 publisher = {IEEE},
 institution = {{Robotics and Automation Society} and {Engineering in Medicine and Biology Society} and {IEEE RAS {\&} EMBS International Conference on Biomedical Robotics and Biomechatronics (BioRob)} and {IEEE RAS {\&} EMBS International Conference on Biomedical Robotics and Biomechatronics} and {Symposium on Surgical Robotics} and {Bioengineering Week}}
}


@proceedings{IasonasOikonomidis.2010,
 year = {2010},
 title = {Markerless and Efficient 26-DOF Hand Pose Recovery},
 urldate = {2017-10-29},
 editor = {{Iasonas Oikonomidis}, Nikolaos Kyriazis and {Antonis A. Argyros}},
 institution = {Springer}
}


@book{IasonOikonomidis.2011,
 author = {{Iason Oikonomidis} and {Nikolaos Kyriazis} and {Antonis A. Argyros}},
 year = {2011},
 title = {Full DOF Tracking of a Hand Interacting with an Object by Modeling Occlusions and Physical Constraints: 6 - 13 Nov. 2011, Barcelona, Spain},
 keywords = {Bildverarbeitung;Computer vision;Congresses;Konferenz;Maschinelles Sehen},
 address = {Piscataway, NJ},
 urldate = {2017-10-12},
 publisher = {IEEE},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE International Conference on Computer Vision} and ICCV}
}


@article{IEEE.,
 author = {IEEE},
 title = {A Four-step Camera Calibration Procedure With Implicit Image Correction - Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference},
 urldate = {2018-02-10}
}


@proceedings{IEEE.2008,
 year = {2008},
 title = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2009,
 year = {2009},
 title = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2009b,
 year = {2009},
 title = {Computer-Aided Design and Computer Graphics, 2009. CAD/Graphics' 09. 11th IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2010,
 year = {2010},
 title = {Communications, Control and Signal Processing (ISCCSP), 2010 4th International Symposium on},
 institution = {IEEE}
}


@proceedings{IEEE.2011,
 year = {2011},
 title = {Automatic Face {\&} Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2011b,
 year = {2011},
 title = {Digital Media and Digital Content Management (DMDCM), 2011 Workshop on},
 institution = {IEEE}
}


@proceedings{IEEE.2011c,
 year = {2011},
 title = {Multimedia and Expo (ICME), 2011 IEEE International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2013,
 year = {2013},
 title = {Digital Image Computing: Techniques and Applications (DICTA), 2013 International Conference on},
 institution = {IEEE}
}


@proceedings{IEEE.2017,
 year = {2017},
 title = {Virtual Reality (VR), 2017 IEEE},
 institution = {IEEE}
}


@proceedings{IEEEComputerSocietyConferenceonComputerVisionandPatternRecognition.1999,
 year = {1999},
 title = {1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition: June 23-25, 1999 Fort Collins, Colorado},
 address = {Los Alamitos, Ca},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0149-4},
 institution = {{IEEE Computer Society Conference on Computer Vision and Pattern Recognition} and {IEEE Computer Society}}
}


@book{IEEEInternationalConferenceonAutomaticFaceandGestureRecognition(FG).1998,
 year = {1998},
 title = {Proceedings},
 address = {Los Alamitos, Calif. [u.a.]},
 publisher = {{IEEE Computer Society}},
 isbn = {9780818683466},
 institution = {{IEEE International Conference on Automatic Face and Gesture Recognition (FG)}}
}


@book{IEEEInternationalConferenceonAutomaticFaceandGestureRecognition.1998,
 year = {1998},
 title = {Proceedings of the third IEEE International Conference on Automatic Face and Gesture Recognition, April 14-16, 1998, Nara, Japan},
 address = {Los Alamitos},
 publisher = {{IEEE Computer Society}},
 isbn = {9780818683442},
 institution = {{IEEE International Conference on Automatic Face and Gesture Recognition}}
}


@proceedings{IEEEWorkshoponMotionofNonRigidandArticulatedObjects.1994,
 year = {1994},
 title = {Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects, November 11-12, 1994, Austin, Texas},
 keywords = {Computer vision;Congresses;Image processing;Motion perception (Vision);Optical pattern recognition},
 address = {Los Alamitos, Calif},
 publisher = {{IEEE Computer Society Press}},
 isbn = {0-8186-6435-5},
 institution = {{IEEE Workshop on Motion of Non-Rigid and Articulated Objects} and {IEEE Computer Society}}
}


@proceedings{InstituteofElectricalandElectronicsEngineers.2008,
 year = {2008},
 title = {IEEE Conference on Computer Vision and Pattern Recognition, 2008: CVPR 2008 ; Anchorage, AK, 23 - 28 June 2008},
 keywords = {Computer vision;Congresses;Kongress;Maschinelles Sehen;Mustererkennung;Pattern recognition systems},
 address = {Piscataway, NJ},
 publisher = {{IEEE Service Center}},
 isbn = {978-1-4244-2242-5},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Conference on Computer Vision and Pattern Recognition} and CVPR}
}


@proceedings{InstituteofElectricalandElectronicsEngineers.2012,
 year = {2012},
 title = {1st International Conference on Recent Advances in Information Technology (RAIT), 2012: Dhanbad, India, 15 - 17 March 2012},
 price = {Compliant PDF},
 keywords = {Congresses;Data encryption (Computer science);Digital techniques;Image processing;Information technology;Telecommunication systems},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4577-0697-4},
 institution = {{Institute of Electrical and Electronics Engineers} and {Indian School of Mines} and {International Conference on Recent Advances in Information Technology} and RAIT}
}


@proceedings{InternationalConferenceonComputerVision.1995,
 year = {1995},
 title = {Proceedings: Fifth International Conference on Computer Vision, June 20-23, 1995, Massachusetts Institute of Technology, Cambridge, Massachusetts},
 keywords = {Computer vision;Congresses},
 address = {Los Alamitos, Calif},
 publisher = {{IEEE Computer Society Press}},
 isbn = {0-8186-7042-8},
 institution = {{International Conference on Computer Vision} and {IEEE Computer Society}}
}


@proceedings{InternationalWorkshoponFibreandOpticalPassiveComponents.2012,
 year = {2012},
 title = {7th International Workshop on Fibre and Optical Passive Components (WFOPC), 2011: 13 - 15 July 2011, Montreal},
 keywords = {Congresses;Fiber optics;Optical communications;Optical fibers;Optoelectronic devices;Passive components},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4577-0861-9},
 institution = {{International Workshop on Fibre and Optical Passive Components} and WFOPC}
}


@book{JamesCooperMihailoAzharTrevorGeeWannesVanDerMarkPatriceDelmasGeorgyGimelfarb.2017,
 abstract = {The 15th IAPR Conference on Machine Vision Applications, May 8-12, 2017, Nagoya University, Nagoya, Japan},
 author = {{James Cooper, Mihailo Azhar, Trevor Gee, Wannes Van Der Mark, Patrice Delmas, Georgy Gimel'farb}},
 year = {2017},
 title = {Proceedings of the fifteenth IAPR International Conference on Machine Vision Applications: May 8-12, 2017, Toyoda Auditorium, Nagoya University, Nagoya, Japan},
 keywords = {Autonomous Vehicles;Maschinelles Sehen;Sensors for 3D/Motion;Sensors for 3D/Motion,Autonomous Vehicles,Tracking;Tracking},
 address = {Piscataway, NJ},
 urldate = {2018-01-17},
 publisher = {IEEE},
 institution = {{IAPR International Conference on Machine Vision Applications} and {International Association for Pattern Recognition} and MVA}
}


@article{JamesJ.Kuch.1995,
 abstract = {In this work, the authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression. The model is able to fitted to any person's hand and can be done using a single camera. Once the model is fitted to a real human hand, it is then used in several tracking scenarios in order to verify its effectiveness. With successful tracking achieved, the model is ready to be incorporated into a virtual environment or model based compression scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks at very low bit rates and at very high image quality.},
 author = {{James J. Kuch} and {Thomas S. Huang}},
 year = {1995},
 title = {Vision Based Hand Modeling and Tracking for Virtual Teleconferencing and Telecollaboration: IEEE Proceedings Fifth International Conference on Computer Vision, June 20-23, 1995, Massachusetts Institute of Technology, Cambridge, Massachusetts},
 keywords = {Computer vision;Congresses},
 urldate = {2017-09-07}
}


@article{JeromeMartin.1998,
 author = {{Jerome Martin} and {Vincent Devin} and {James L. Crowley}},
 year = {1998},
 title = {Active Hand Tracking},
 urldate = {2017-11-02},
 journal = {Third International IEEE Conference on Automatic Face and Gesture Recognition}
}


@inproceedings{Kato.1999,
 author = {Kato, H. and Billinghurst, M.},
 title = {Marker tracking and HMD calibration for a video-based augmented reality conferencing system},
 urldate = {2017-10-05},
 pages = {85--94},
 bookpagination = {page},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0359-4},
 editor = {{Hirokazu Kato} and {Mark Billinghurst}},
 booktitle = {Marker tracking and HMD calibration for a video-based augmentedreality conferencing system},
 year = {1999},
 address = {Los Alamitos, Calif},
 doi = {10.1109/IWAR.1999.803809}
}


@article{Kim.2015,
 author = {Kim, Kwangtaek and Kim, Joongrock and Choi, Jaesung and Kim, Junghyun and Lee, Sangyoun},
 year = {2015},
 title = {Depth camera-based 3D hand gesture controls with immersive tactile feedback for natural mid-air gesture interactions},
 pages = {1022--1046},
 pagination = {page},
 volume = {15},
 number = {1},
 journal = {Sensors}
}


@book{Kimmel.2011,
 year = {2011},
 title = {Computer vision - ACCV 2010: 10th Asian Conference on Computer Vision, Queenstown, New Zealand, November 8 - 12, 2010 ; revised selected papers, part III},
 keywords = {Artificial intelligence;Computer graphics;Computer science;Computer software;Computer vision;Optical pattern recognition;Visualization},
 address = {Berlin},
 volume = {6494},
 publisher = {Springer},
 isbn = {978-3-642-19318-7},
 series = {Lecture Notes in Computer Science},
 editor = {Kimmel, Ron and Klette, Reinhard and Sugimoto, Akihiro},
 doi = {10.1007/978-3-642-19318-7}
}


@book{Kimmel.2011b,
 year = {2011},
 title = {Computer Vision -- ACCV 2010: 10th Asian Conference on Computer Vision, Queenstown, New Zealand, November 8-12, 2010, Revised Selected Papers, Part III},
 address = {Berlin, Heidelberg},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-19318-7},
 editor = {Kimmel, Ron and Klette, Reinhard and Sugimoto, Akihiro}
}


@book{Korein.1985,
 author = {Korein, James Urey},
 year = {1985},
 title = {A geometric investigation of reach: Zugl.: Pennsylvania Univ., Diss. : 1984},
 keywords = {11030;20020;21030;31030;anthropometric aspects;industrial;kinematics;Links and link-motion;Machinery, Kinematics of;manipulators;p1030;Robotics;robots},
 address = {Cambridge, Mass.},
 publisher = {{MIT Press}},
 isbn = {0262111047},
 series = {ACM distinguished dissertations}
}


@incollection{Kristensen.Feb.2007,
 abstract = {To efficiently classify and track video objects in a surveillance application, it is essential to reduce the amount of streaming data. One solution is to segment the video into background, i.e. stationary objects, and foreground, i.e. moving objects, and then discard the background. One such motion segmentation algorithm that has proven reliable is the Stauffer and Grimson algorithm. This paper investigates how different color spaces affect the segmentation result in terms of noise and shadow sensitivity. Shadows are especially problematic since they not only distort shape but can also result in falsely connected objects that will complicate tracking and classification. Therefore, a new decision kernel for the segmentation algorithm is presented. This kernel alters the probability of foreground detection to reduce shadows and to increase the chance of correct segmentation for objects with a skin tone color, e.g. faces.},
 author = {Kristensen, Fredrik and Nilsson, Peter and {\"O}wall, Viktor},
 title = {Background Segmentation Beyond RGB},
 pages = {602--612},
 bookpagination = {page},
 publisher = {{Springer London}},
 isbn = {978-3-540-32432-4},
 editor = {Narayanan, P. J. and Nayar, Shree K. and Shum, Heung-Yeung},
 booktitle = {Computer Vision - ACCV 2006},
 year = {Feb. 2007},
 address = {Guildford}
}


@inproceedings{Kuch.1995,
 author = {Kuch, J. J. and Huang, T. S.},
 title = {Vision based hand modeling and tracking for virtual teleconferencing and telecollaboration},
 pages = {666--671},
 bookpagination = {page},
 publisher = {{IEEE Computer Society Press}},
 isbn = {0-8186-7042-8},
 booktitle = {Proceedings},
 year = {1995},
 address = {Los Alamitos, Calif},
 doi = {10.1109/ICCV.1995.466875}
}


@inproceedings{Kumar.2012,
 author = {Kumar, Piyush and Rautaray, Siddharth S. and Agrawal, Anupam},
 title = {Hand data glove: A new generation real-time mouse for Human-Computer Interaction},
 pages = {750--755},
 bookpagination = {page},
 publisher = {IEEE},
 isbn = {978-1-4577-0697-4},
 booktitle = {1st International Conference on Recent Advances in Information Technology (RAIT), 2012},
 year = {2012},
 address = {Piscataway, NJ},
 doi = {10.1109/RAIT.2012.6194548}
}


@inproceedings{Kuroda.2004,
 author = {Kuroda, T. and Tabata, Y. and Goto, A. and Ikuta, H. and Murakami, M. and others},
 title = {Consumer price data-glove for sign language recognition},
 pages = {253--258},
 bookpagination = {page},
 booktitle = {Proc. of 5th Intl Conf. Disability, Virtual Reality Assoc. Tech., Oxford, UK},
 year = {2004}
}


@inproceedings{LaGorce.2008,
 abstract = {A novel model-based approach to 3D hand tracking from monocular video is presented. The 3D hand pose, the hand texture and the illuminant are dynamically estimated through minimization of an objective function. Derived from an inverse problem formulation, the objective function enables explicit use oftexture temporal continuity and shading information, while handling important self-occlusions and time-varying illumination. The minimization is done efficiently using a quasi-Newton method, for which we propose a rigorous derivation of the objective function gradient. Particular attention is given to terms related to the change of visibility near self-occlusion boundaries that are neglected in existing formulations. In doing so we introduce new occlusion forces and show that using all gradient terms greatly improves the performance of the method. Experimental results demonstrate the potential ofthe formulation.},
 author = {de {La Gorce}, Martin and Paragios, Nikos and Fleet, David J.},
 title = {Model-based hand tracking with texture, shading and self-occlusions},
 pages = {1--8},
 bookpagination = {page},
 publisher = {{IEEE Service Center}},
 isbn = {978-1-4244-2242-5},
 booktitle = {IEEE Conference on Computer Vision and Pattern Recognition, 2008},
 year = {2008},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPR.2008.4587752}
}


@article{Lansley.2016,
 author = {Lansley, Alastair and Vamplew, Peter and Smith, Philip and Foale, Cameron},
 year = {2016},
 title = {Caliko: An Inverse Kinematics Software Library Implementation of the FABRIK Algorithm},
 url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.116/galley/192/download/},
 keywords = {FABRIK;IK;Inverse;Java;kinematics;Leap;Library;Robotics;Software},
 volume = {4},
 number = {1},
 issn = {2049-9647},
 journal = {Journal of Open Research Software},
 doi = {10.5334/jors.116}
}


@article{Lee.1995,
 author = {Lee, Jintae and Kunii, T. L.},
 year = {1995},
 title = {Model-based analysis of hand posture},
 pages = {77--86},
 pagination = {page},
 volume = {15},
 number = {5},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/38.403831}
}


@article{Lepetit.2005,
 author = {Lepetit, Vincent and Fua, Pascal},
 year = {2005},
 title = {Monocular Model-Based 3D Tracking of Rigid Objects: A Survey},
 pages = {1--89},
 pagination = {page},
 volume = {1},
 number = {1},
 issn = {1572-2740},
 journal = {Foundations and Trends{\circledR} in Computer Graphics and Vision},
 doi = {10.1561/0600000001}
}


@proceedings{Levoy.2007,
 year = {2007},
 title = {SIGGRAPH 2007: San Diego, California, USA, 5 - 9 August 2007 ; full conference DVD},
 keywords = {Computeranimation;Computergrafik;Computerkunst;Kongress},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {9781595936486},
 editor = {Levoy, Marc},
 institution = {{Association for Computing Machinery} and SIGGRAPH and {ACM SIGGRAPH 2007 conference}},
 doi = {10.1145/1275808}
}


@article{Lien.1998,
 abstract = {Conventional model-based hand gesture analysis systems require high computation cost to solve the finger inverse kinematics that makes them very difficult for real-time implementation. In this paper, we propose a fast hand model fitting method for the tracking of hand motion. The model fitting method consists of (1) finding the closed-form inverse kinematics solution for the finger fitting process, and (2) defining the alignment measure for the wrist fitting process. In the experiments, we illustrate that our hand model fitting method is effective and real-time implementable.},
 author = {Lien, Cheng-Chang and Huang, Chung-Lin},
 year = {1998},
 title = {Model-based articulated hand motion tracking for gesture recognition},
 keywords = {Finger inverse Kinematics;Gesture Recognition;Model based techniques;Realtime implementable hand motion tracking},
 pages = {121--134},
 pagination = {page},
 volume = {16},
 number = {2},
 journal = {Image and Vision Computing},
 doi = {10.1016/S0262-8856(97)00041-3}
}


@inproceedings{Lin.2000,
 abstract = {Hand motion capturing is one of the most important parts of gesture interfaces. Many current approaches to this task generally involve a formidable nonlinear optimization problem in a large search space. Motion capturing can be achieved more cost-efficiently when considering the motion constraints of a hand. Although some constraints can be represented as equalities or inequalities, there exist many constraints, which cannot be explicitly represented. In this paper, we propose a learning approach to model the hand configuration space directly. The redundancy of the configuration space can be eliminated by finding a lower-dimensional subspace of the original space. Finger motion is modeled in this subspace based on the linear behavior observed in the real motion data collected by a CyberGlove. Employing the constrained motion model, we are able to efficiently capture finger motion from video inputs. Several experiments show that our proposed model is helpful for capturing articulated motion.},
 author = {Lin, John and Wu, Ying and Huang, T. S.},
 title = {Modeling the constraints of human hand motion},
 pages = {121--126},
 bookpagination = {page},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0939-8},
 booktitle = {Proceedings, Workshop on Human Motion},
 year = {2000},
 address = {Los Alamitos, Calif},
 doi = {10.1109/HUMO.2000.897381}
}


@article{Lucas.2016,
 abstract = {TeX output 2000.10.11:1429},
 author = {Lucas, Stuart R. and Tischler, Craig R. and Samuel, Andrew E.},
 year = {2016},
 title = {Real-Time Solution of the Inverse Kinematic-Rate Problem},
 urldate = {2017-09-22},
 pages = {1236--1244},
 pagination = {page},
 volume = {19},
 number = {12},
 issn = {0278-3649},
 journal = {The International Journal of Robotics Research},
 doi = {10.1177/02783640022068057}
}


@misc{M.Roth.1999,
 abstract = {Vision can be a powerful interface device for computers because of its potential for sensing body position, head orientation, direction of gaze, pointing c},
 author = {{M. Roth} and {K. Tanaka} and {C. Weissman} and {W. Yerazunis}},
 year = {1999},
 title = {Computer Vision for Interactive Computer Graphics},
 url = {http://ieeexplore.ieee.org/abstract/document/674971/},
 urldate = {2017-08-13},
 number = {May-June}
}


@inproceedings{MacCormick.2000,
 author = {MacCormick, John and Isard, Michael},
 title = {Partitioned sampling, articulated objects, and interface-quality hand tracking},
 pages = {3--19},
 bookpagination = {page},
 booktitle = {European Conference on Computer Vision},
 year = {2000}
}


@inproceedings{Majeau.2012,
 author = {Majeau, L. and Borduas, J. and Loranger, S. and El-Iraki, Y. and Lavoie, J. and Banville, D. and Latendresse, V. and Beland, V. and Daniel-Rivest, J. and Thiaw, A. and Bambara, H. and Beausoleil, T. P. and Trottier-Lapointe, W. and Lapointe, J.},
 title = {Dataglove for consumer applications: Low cost dataglove using optical fiber sensor},
 pages = {1--4},
 bookpagination = {page},
 publisher = {IEEE},
 isbn = {978-1-4577-0861-9},
 booktitle = {7th International Workshop on Fibre and Optical Passive Components (WFOPC), 2011},
 year = {2012},
 address = {Piscataway, NJ},
 doi = {10.1109/WFOPC.2011.6089679}
}


@inproceedings{Mauthner.2008,
 author = {Mauthner, Thomas and Donoser, Michael and Bischof, Horst},
 title = {Robust tracking of spatial related components},
 pages = {1--4},
 bookpagination = {page},
 booktitle = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
 year = {2008}
}


@book{MichaelGirard.1985,
 author = {{Michael Girard} and {A. A. Maciejewski}},
 year = {1985},
 title = {Computational Modeling for the Computer Animation of Legged Figures},
 keywords = {Computer science},
 address = {New York, NY},
 urldate = {2017-09-22},
 publisher = {ACM},
 institution = {{12TH Annual Conference on Computer Graphics 1985} and {ACM Special Interest Group on Computer Graphics and Interactive Techniques}}
}


@inproceedings{Mo.2005,
 author = {Mo, Zhenyao and Lewis, J. P. and Neumann, Ulrich},
 title = {SmartCanvas},
 pages = {239},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {1581138946},
 editor = {{St. Amant}, Rob},
 booktitle = {Proceedings of the 10th international conference on Intelligent user interfaces},
 year = {2005},
 address = {New York, NY},
 doi = {10.1145/1040830.1040881}
}


@article{ModMaasum.2015,
 abstract = {Hand gesture recognition system has evolved tremendously in the recent few years because of its ability to interact with machine efficiently. Mankind tries to incorporate human gestures into modern technology by searching and finding a replacement of multi touch technology which does not require any touching movement on screen. This paper presents an overview on several methods to realize hand gesture recognition by using three main modules: camera and segmentation module, detection module and feature extraction module. There are many methods which can be used to get the respective results depending on its advantages. Summary of previous research and results of hand gesture methods as well as comparison between gesture recognition are also given in this paper.},
 author = {{Mod Ma'asum}, Farah Farhana and Sulaiman, Suhana and Saparon, Azilah},
 year = {2015},
 title = {An Overview of Hand Gestures Recognition System Techniques},
 pages = {012012},
 pagination = {page},
 volume = {99},
 issn = {1757-8981},
 journal = {IOP Conference Series: Materials Science and Engineering},
 doi = {10.1088/1757-899X/99/1/012012}
}


@article{Moeslund.2001,
 author = {Moeslund, Thomas B. and Granum, Erik},
 year = {2001},
 title = {A Survey of Computer Vision-Based Human Motion Capture},
 pages = {231--268},
 pagination = {page},
 volume = {81},
 number = {3},
 journal = {Computer vision and image understanding},
 doi = {10.1006/cviu.2000.0897}
}


@article{Moeslund.2006,
 author = {Moeslund, Thomas B. and Hilton, Adrian and Kr{\"u}ger, Volker},
 year = {2006},
 title = {A survey of advances in vision-based human motion capture and analysis},
 pages = {90--126},
 pagination = {page},
 volume = {104},
 number = {2-3},
 journal = {Computer vision and image understanding},
 doi = {10.1016/j.cviu.2006.08.002}
}


@article{Nakamura.1986,
 author = {Nakamura, Yoshihiko and Hanafusa, Hideo},
 year = {1986},
 title = {Inverse Kinematic Solutions With Singularity Robustness for Robot Manipulator Control},
 pages = {163},
 pagination = {page},
 volume = {108},
 number = {3},
 issn = {00220434},
 journal = {Journal of Dynamic Systems, Measurement, and Control},
 doi = {10.1115/1.3143764}
}


@book{Narayanan.Feb.2007,
 abstract = {Annotation},
 year = {Feb. 2007},
 title = {Computer Vision - ACCV 2006: 7th Asian Conference on Computer Vision, Hyderabad, India, January 13-16, 2006, Proceedings, Part II},
 address = {Guildford},
 publisher = {{Springer London}},
 isbn = {978-3-540-32432-4},
 editor = {Narayanan, P. J. and Nayar, Shree K. and Shum, Heung-Yeung}
}


@book{Nirei.1996,
 author = {Nirei, Kenichi and Saito, Hideo and Mochimaru, Masaaki and Ozawa, Shinji},
 year = {1996},
 title = {Human Hand Tracking from Binocular Image Sequences: Proceedings of the 1996 IEEE IECON 22nd International Conference on Industrial Electronics, Control, and Instrumentation},
 keywords = {Automation;Congresses;Electronic control;Industrial electronics;Power electronics;Robotics},
 address = {New York and Piscataway N.J.},
 urldate = {2017-10-05},
 publisher = {{Institute of Electrical and Electronics Engineers} and {Can be ordered from IEEE Service Center}},
 institution = {{Institute of Electrical and Electronics Engineers}}
}


@article{Nolastname!.,
 abstract = {IEEE Transactions on Magnetics},
 author = {{Aniq Masood}},
 title = {Stereo Pi: Portable Digital Stereo Camera},
 url = {https://web.stanford.edu/class/ee367/Winter2016/Masood_Report.pdf},
 urldate = {2018-01-09}
}


@incollection{Oikonomidis.2011,
 abstract = {We present a novel method that, given a sequence of synchronized views of a human hand, recovers its 3D position, orientation and full articulation parameters. The adopted hand model is based on properly selected and assembled 3D geometric primitives. Hypothesized configurations/poses of the hand model are projected to different camera views and image features such as edge maps and hand silhouettes are computed. An objective function is then used to quantify the discrepancy between the predicted and the actual, observed features. The recovery of the 3D hand pose amounts to estimating the parameters that minimize this objective function which is performed using Particle Swarm Optimization. All the basic components of the method (feature extraction, objective function evaluation, optimization process) are inherently parallel. Thus, a GPU-based implementation achieves a speedup of two orders of magnitude over the case of CPU processing. Extensive experimental results demonstrate qualitatively and quantitatively that accurate 3D pose recovery of a hand can be achieved robustly at a rate that greatly outperforms the current state of the art.},
 author = {Oikonomidis, Iasonas and Kyriazis, Nikolaos and Argyros, Antonis A.},
 title = {Markerless and Efficient 26-DOF Hand Pose Recovery},
 url = {https://doi.org/10.1007/978-3-642-19318-7_58},
 pages = {744--757},
 bookpagination = {page},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-19318-7},
 editor = {Kimmel, Ron and Klette, Reinhard and Sugimoto, Akihiro},
 booktitle = {Computer Vision -- ACCV 2010: 10th Asian Conference on Computer Vision, Queenstown, New Zealand, November 8-12, 2010, Revised Selected Papers, Part III},
 year = {2011},
 address = {Berlin, Heidelberg},
 doi = {10.1007/978-3-642-19318-7_58}
}


@misc{Opencv.2018,
 author = {Opencv},
 year = {2018},
 title = {Camera Calibration},
 url = {https://docs.opencv.org/3.1.0/dc/dbb/tutorial_py_calibration.html},
 urldate = {2018-02-10}
}


@misc{optitrack.2017,
 author = {optitrack},
 year = {2017},
 title = {flex13MocapVolume.png (680$\times$375)},
 url = {http://www.optitrack.com/public/images/flex13MocapVolume.png},
 urldate = {2017-09-29}
}


@article{Orin.1984,
 abstract = {This paper discusses and compares six different methods for calculating the Jacobian for a manipulator. We enumerate the computational efficiency of each in terms general N- degree-of-freedom of the total number of multiplications, addiof the number of matrix-vector operations

tions/subtractions, and trigonometric functions required as well as in terms

needed. We also give the execution times on a

minicomputer for determining the Jacobian for an

of the best new

PDP-11/70 example seven-degree-of-freedom manipulator. This paper formulates one

methods for determining the Jacobian.},
 author = {Orin, David E. and Schrader, William W.},
 year = {1984},
 title = {Efficient Computation of the Jacobian for Robot Manipulators},
 urldate = {2017-09-22},
 volume = {Vol.3},
 number = {No.4},
 issn = {0278-3649},
 journal = {The International Journal of Robotics Research}
}


@inproceedings{Pan.2017,
 author = {Pan, Matthew KXJ and Niemeyer, G{\"u}nter},
 title = {Catching a real ball in virtual reality},
 pages = {269--270},
 bookpagination = {page},
 booktitle = {Virtual Reality (VR), 2017 IEEE},
 year = {2017}
}


@article{PaulJ.BeslNeilD.McKay.1992,
 author = {{Paul J. Besl, Neil D.McKay}},
 year = {1992},
 title = {A method for registration of 3-D shapes - Pattern Analysis and Machine Intelligence,},
 keywords = {3D Object registration Overview of registration methods in early years},
 urldate = {2017-08-17},
 journal = {IEEE transactions on pattern analysis and machine intelligence}
}


@article{Pavlovic.1997,
 author = {Pavlovic, V. I. and Sharma, R. and Huang, T. S.},
 year = {1997},
 title = {Visual interpretation of hand gestures for human-computer interaction: A review},
 pages = {677--695},
 pagination = {page},
 volume = {19},
 number = {7},
 issn = {01628828},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 doi = {10.1109/34.598226}
}


@article{Penrose.1956,
 abstract = {Mathematical Proceedings of the Cambridge Philosophical Society},
 author = {Penrose, R. and Todd, J. A.},
 year = {1956},
 title = {On best approximate solutions of linear matrix equations},
 urldate = {2017-09-22},
 pages = {17},
 pagination = {page},
 volume = {52},
 number = {01},
 issn = {0305-0041},
 journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
 doi = {10.1017/S0305004100030929}
}


@article{Poppe.2007,
 author = {Poppe, Ronald},
 year = {2007},
 title = {Vision-based human motion analysis: An overview},
 urldate = {2018-01-11},
 pages = {4--18},
 pagination = {page},
 volume = {108},
 number = {1-2},
 journal = {Computer vision and image understanding},
 doi = {10.1016/j.cviu.2006.10.016}
}


@inproceedings{Prisacariu.2011,
 author = {Prisacariu, Victor Adrian and Reid, Ian},
 title = {Robust 3D hand tracking for human computer interaction},
 pages = {368--375},
 bookpagination = {page},
 booktitle = {Automatic Face {\&} Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
 year = {2011}
}


@inproceedings{Qian.2014,
 author = {Qian, Chen and Sun, Xiao and Wei, Yichen and Tang, Xiaoou and Sun, Jian},
 title = {Realtime and robust hand tracking from depth},
 pages = {1106--1113},
 bookpagination = {page},
 booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
 year = {2014}
}


@article{Raab.1979,
 author = {Raab, Frederick and Blood, Ernest and Steiner, Terry and Jones, Herbert},
 year = {1979},
 title = {Magnetic Position and Orientation Tracking System},
 pages = {709--718},
 pagination = {page},
 volume = {AES-15},
 number = {5},
 issn = {0018-9251},
 journal = {IEEE Transactions on Aerospace and Electronic Systems},
 doi = {10.1109/TAES.1979.308860}
}


@article{Rautaray.2015,
 abstract = {As computers become more pervasive in society, facilitating natural human--computer interaction (HCI) will have a positive impact on their use. Hence, there has been growing interest in the development of new approaches and technologies for bridging the human--computer barrier. The ultimate aim is to bring HCI to a regime where interactions with computers will be as natural as an interaction between humans, and to this end, incorporating gestures in HCI is an important research area. Gestures have long been considered as an interaction technique that can potentially deliver more natural, creative and intuitive methods for communicating with our computers. This paper provides an analysis of comparative surveys done in this area. The use of hand gestures as a natural interface serves as a motivating force for research in gesture taxonomies, its representations and recognition techniques, software platforms and frameworks which is discussed briefly in this paper. It focuses on the three main phases of hand gesture recognition i.e. detection, tracking and recognition. Different application which employs hand gestures for efficient interaction has been discussed under core and advanced application domains. This paper also provides an analysis of existing literature related to gesture recognition systems for human computer interaction by categorizing it under different key parameters. It further discusses the advances that are needed to further improvise the present hand gesture recognition systems for future perspective that can be widely used for efficient human computer interaction. The main goal of this survey is to provide researchers in the field of gesture based HCI with a summary of progress achieved to date and to help identify areas where further research is needed.},
 author = {Rautaray, Siddharth S. and Agrawal, Anupam},
 year = {2015},
 title = {Vision based hand gesture recognition for human computer interaction: A survey},
 pages = {1--54},
 pagination = {page},
 volume = {43},
 number = {1},
 issn = {1573-7462},
 journal = {Artificial Intelligence Review},
 doi = {10.1007/s10462-012-9356-9}
}


@inproceedings{Rehg.1994,
 author = {Rehg, James M. and Kanade, Takeo},
 title = {Visual tracking of high dof articulated structures: An application to human hand tracking},
 pages = {35--46},
 bookpagination = {page},
 booktitle = {European conference on computer vision},
 year = {1994}
}


@inproceedings{Rehg.1994b,
 author = {Rehg, J. M. and Kanade, T.},
 title = {DigitEyes: vision-based hand tracking for human-computer interaction},
 pages = {16--22},
 bookpagination = {page},
 publisher = {{IEEE Computer Society Press}},
 isbn = {0-8186-6435-5},
 booktitle = {Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects, November 11-12, 1994, Austin, Texas},
 year = {1994},
 address = {Los Alamitos, Calif},
 doi = {10.1109/MNRAO.1994.346260}
}


@article{Richards.1999,
 author = {Richards, James G.},
 year = {1999},
 title = {The measurement of human motion: A comparison of commercially available systems},
 pages = {589--602},
 pagination = {page},
 volume = {18},
 number = {5},
 issn = {01679457},
 journal = {Human Movement Science},
 doi = {10.1016/S0167-9457(99)00023-8}
}


@misc{RichardWatson.1993,
 author = {{Richard Watson}},
 date = {1993},
 title = {A Survey of Gesture Recognition Techniques},
 address = {Dublin},
 urldate = {2017-10-29},
 institution = {{Department of Computer Science,Trinity College}}
}


@inproceedings{Rijpkema.1991,
 author = {Rijpkema, Hans and Girard, Michael},
 title = {Computer animation of knowledge-based human grasping},
 urldate = {2017-09-15},
 pages = {339--348},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {0897914368},
 editor = {Thomas, James J.},
 booktitle = {Proceedings of the 18th annual conference on Computer graphics and interactive techniques},
 year = {1991},
 address = {New York, NY},
 doi = {10.1145/122718.122754}
}


@article{Rolland.2001,
 abstract = {Tracking for virtual environments is necessary to record the position and the orientation of real objects in physical space and to allow spatial consistency between real and virtual objects. This paper presents a top-down classification of tracking technologies aimed more specifically at head tracking, organized in accordance with their physical principles of operation. Six main principles were identified: time of flight (TOF), spatial scan, inertial sensing, mechanical linkages, phase-difference sensing, and direct-field sensing. We briefly describe each physical principle and present implementations of that principle. Advantages and limitations of these implementations are discussed and summarized in tabular form. A few hybrid technologies are then presented and general considerations of tracking technology are discussed.},
 author = {Rolland, Jannick P. and Baillot, Yohan and Goon, Alexei A.},
 year = {2001},
 title = {A SURVEY OF TRACKING TECHNOLOGY FOR VIRTUAL ENVIRONMENTS: Center for Research and Education in Optics and Lasers (CREOL) University of Central Florida, Orlando FL 32816},
 urldate = {2017-10-05},
 journal = {(Fundamentals of wearable computers and augumented reality}
}


@article{Rosenberg.1999,
 author = {Rosenberg, R. and Slater, M.},
 year = {1999},
 title = {The chording glove: A glove-based text input device},
 pages = {186--191},
 pagination = {page},
 volume = {29},
 number = {2},
 issn = {1094-6977},
 journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
 doi = {10.1109/5326.760563}
}


@article{RUDRAPKPOUDEL.2014,
 author = {{RUDRA P K POUDEL}},
 year = {2014},
 title = {3D Hand Tracking: A thesis submitted in partial fulfilment of the requirements of Bournemouth University for the degree of Doctor of Philosophy},
 urldate = {2017-08-17}
}


@article{SamuelR.Buss.2009,
 author = {{Samuel R. Buss}},
 year = {2009},
 title = {Introduction to Inverse Kinematics with Jacobian Transpose, Pseudoinverse and Damped Least Squares methods},
 urldate = {2017-10-06}
}


@article{Sangineto.2012,
 abstract = {Over the past few years there has been a growing interest in visual interfaces based on gestures. Using

gestures as a mean to communicate with a computer can be helpful in applications such as gaming platforms,

domotic environments, augmented reality or sign language interpretation to name a few. However, a serious

bottleneck for such interfaces is the current lack of accurate hand localization systems, which are necessary

for tracking (re-)initialization and hand pose understanding. In fact, human hand is an articulated object with

a very large degree of appearance variability which is difficult to deal with. For instance, recent attempts to

solve this problem using machine learning approaches have shown poor generalization capabilities over

different viewpoints and finger spatial configurations.

In this article we present a model based approach to articulated hand detection which splits this variability

problem by separately searching for simple finger models in the input image. A generic finger silhouette is

localized in the edge map of the input image by combining curve and graph matching techniques. Cluttered

backgrounds and thick textured images, which usually make it hard to compare edge information with

silhouette models (e.g., using chamfer distance or voting based methods) are dealt with in our approach

by simultaneously using connected curves and topological information. Finally, detected fingers are clustered

using geometric constraints. Our system is able to localize in real time a hand with variable finger configurations

in images with complex backgrounds, different lighting conditions and different positions of the hand

with respect to the camera. Experiments with real images and videos and a simple visual interface are

presented to validate the proposed method.},
 author = {Sangineto, Enver and Cupelli, Marco},
 year = {2012},
 title = {Real-time viewpoint-invariant hand localization with cluttered backgrounds},
 keywords = {Articulated object recognition;Curve matching;Geometric constraints;Graph matching;Hand detection;Model based techniques},
 pages = {26--37},
 pagination = {page},
 volume = {30},
 number = {1},
 journal = {Image and Vision Computing}
}


@inproceedings{Segen.1999,
 author = {Segen, J. and Kumar, S.},
 title = {Shadow gestures: 3D hand pose estimation using a single camera},
 pages = {479--485},
 bookpagination = {page},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0149-4},
 booktitle = {1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
 year = {1999},
 address = {Los Alamitos, Ca},
 doi = {10.1109/CVPR.1999.786981}
}


@article{Shan.2007,
 author = {Shan, Caifeng and Tan, Tieniu and Wei, Yucheng},
 year = {2007},
 title = {Real-time hand tracking using a mean shift embedded particle filter},
 pages = {1958--1970},
 pagination = {page},
 volume = {40},
 number = {7},
 journal = {Pattern recognition}
}


@book{Spong.2008,
 author = {Spong, Mark W. and Vidyasagar, Mathukumalli},
 year = {2008},
 title = {Robot dynamics and control},
 publisher = {{John Wiley {\&} Sons}}
}


@proceedings{Springer.1994,
 year = {1994},
 title = {European conference on computer vision},
 institution = {Springer}
}


@proceedings{Springer.2000,
 year = {2000},
 title = {European Conference on Computer Vision},
 institution = {Springer}
}


@article{SrinathSridharAnttiOulasvirtaChristianTheobalt.2014,
 abstract = {Using hand gestures as input in human--computer interaction is of everincreasing interest. Markerless tracking of hands and fingers is a promising enabler, but adoption has been hampered because of tracking problems, complex and dense capture setups, high computing requirements, equipment costs, and poor latency. In this paper, we present a method that addresses these issues. Our method tracks rapid and complex articulations of the hand using a single depth camera. It is fast (50 fps without GPU support) and supports varying close-range camera-to-scene arrangements, such as in desktop or egocentric settings, where the camera can even move. We frame pose estimation as an optimization problem in depth using a new objective function based on a collection of Gaussian functions, focusing particularly on robust tracking of finger articulations. We demonstrate the benefits of the method in several interaction applications ranging from manipulating objects in a 3D blocks world to egocentric interaction on the go. We also present extensive evaluation of our method on publicly available datasets which shows that our method achieves competitive accuracy.},
 author = {{Srinath Sridhar, Antti Oulasvirta, Christian Theobalt}},
 year = {2014},
 title = {Fast Tracking of Hand and Finger Articulations Using a Single Depth Camera},
 keywords = {3D Interaction;Hand tracking;realtime Tracking},
 urldate = {2017-08-17}
}


@proceedings{St.Amant.2005,
 year = {2005},
 title = {Proceedings of the 10th international conference on Intelligent user interfaces},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {1581138946},
 editor = {{St. Amant}, Rob},
 institution = {{ACM Special Interest Group on Artificial Intelligence} and {ACM Special Interest Group on Computer-Human Interaction}},
 doi = {10.1145/1040830}
}


@inproceedings{Stauffer.1999,
 author = {Stauffer, C. and Grimson, W.E.L.},
 title = {Adaptive background mixture models for real-time tracking},
 pages = {246--252},
 bookpagination = {page},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0149-4},
 booktitle = {1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
 year = {1999},
 address = {Los Alamitos, Ca},
 doi = {10.1109/CVPR.1999.784637}
}


@article{Stenger.,
 abstract = {This paper presents a practical technique for modelbased 3D hand tracking. An anatomically accurate hand model is built from truncated quadrics. This allows for the generation of2D profiles ofthe model using elegant tools from projective geometry, and for an efficient method to handle self-occlusion. The pose ofthe hand model is estimated with an Unscented Kalman filter (UKF), which minimizes the geometric error between the profiles andedges extracted from the images. The use ofthe UKF permits higher frame rates than more sophisticated estimation methods such as particle filtering, whilst providing higher accuracy than the extended Kalman filter. The system is easily scalable from single to multiple views, and from rigid to articulated models. First experiments on real data using one and two cameras demonstrate the quality of the proposed method for tracking a 7 DOF hand model.},
 author = {Stenger and Mendoca and Cipolla},
 title = {Model-Based 3D Tracking of an Articulated Hand},
 urldate = {2017-08-25}
}


@inproceedings{Stenger.2001,
 abstract = {This paper presents a novel method for hand tracking. It uses a 3D model built from quadrics which approximates the anatomy of a human hand. This approach allows for the use of results from projective geometry that yield an elegant technique to generate the projection ofthe model as a set ofconics, as well as providing an efficient ray tracing algorithm to handle self-occlusion. Once the model is projected, an Unscented Kalman Filter is used to update its pose in order to minimise the geometric error between the model projection and a video sequence on the background. Results from experiments with real data show the accuracy of the technique.},
 author = {Stenger, Bjoern and Mendon{\c{c}}a, Paulo R. S. and Cipolla, Roberto},
 title = {Model-Based Hand Tracking Using an Unscented Kalman Filter},
 pages = {63--72},
 bookpagination = {page},
 volume = {1},
 booktitle = {BMVC},
 year = {2001}
}


@article{Stenger.2006,
 abstract = {This thesis focuses on the automatic recovery of three-dimensional hand motion from one or more views. A 3D geometric hand model is constructed from truncated cones, cylinders and ellipsoids and is used to generate contours, which can be compared with edge contours and skin colour in images. The hand tracking problem is formulated as state estimation, where the model parameters define the internal state, which is to be estimated from image observations.

In the first approach, an unscented Kalman filter is employed to update the model's pose based on local intensity or skin colour edges. The algorithm is able to track smooth hand motion in front of backgrounds that are either uniform or contain no skin colour. However, manual initialization is required in the first frame, and no recovery strategy is available when track is lost.

The second approach, tree-based filtering, combines ideas from detection and Bayesian filtering: Detection is used to solve the initialization problem, where a single image is given with no prior information of the hand pose. A hierarchical Bayesian filter is developed, which allows integration of temporal information. This is more efficient than applying detection at each frame, because dynamic information can be incorporated into the search, which helps to resolve ambiguities in difficult cases. This thesis develops a likelihood function, which is based on intensity edges, as well as pixel colour values. This function is obtained from a similarity measure, which is compared with a number of other cost functions. The posterior distribution is computed in a hierarchical fashion, the aim being to concentrate computation power on regions in state space with larger posterior values. The algorithm is tested on a number of image sequences, which include hand motion with self-occlusion in front of a cluttered background.},
 author = {Stenger, Bj{\"o}rn and Thayananthan, Arasanathan and Torr, Philip H. S. and Cipolla, Roberto},
 year = {2006},
 title = {Model-based hand tracking using a hierarchical bayesian filter},
 pages = {1372--1384},
 pagination = {page},
 volume = {28},
 number = {9},
 journal = {IEEE transactions on pattern analysis and machine intelligence}
}


@article{Sturman.1994,
 abstract = {Our primary physical connection to the world is through our hands. We perform most everyday tasks with them. How- ever, when we work with a computer or computer-controlled ap- plication, we are constrained by clumsy intermediary devices such as keyboards, mice, and joysticks. Little of the dexterity and nat- uralness that characterize our hands transfers to the task itself. In an effort to change this, people have been designing, build- ing, and studying ways of getting computers to ``read'' users' hands directly, free from the limitations of intermediary de- vices. The development of electronic gloves has been an im- portant step in this direction. The commercialization and widespread availability of devices such as the VPL DataGlove and the Matte1 Power Glove has led to an explosion of research and development projects using electronic gloves as interfaces to computer applications and computer-controlled devices. The applications span fields as diverse as telemanipulation, virtual reality, medicine, scientific visualization, puppetry, music, and video games. In this article we provide a basis for understanding the field by describing key hand-tracking technologies and applications using glove-based input. The bulk of development in glove- based input has taken place very recently, and not all of it is easily accessible in the literature. We present here a cross-sec- tion of the field to date.},
 author = {Sturman, D. J. and Zeltzer, D.},
 year = {1994},
 title = {A survey of glove-based input},
 urldate = {2017-09-29},
 pages = {30--39},
 pagination = {page},
 volume = {14},
 number = {1},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/38.250916}
}


@inproceedings{Sun.2009,
 author = {Sun, Li and Klank, Ulrich and Beetz, Michael},
 title = {EYEWATCHME---3D hand and object tracking for inside out activity analysis},
 pages = {9--16},
 bookpagination = {page},
 booktitle = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
 year = {2009}
}


@inproceedings{Sun.2011,
 author = {Sun, Li and Liu, Guizhong},
 title = {Hand tracking based on the combination of 2D and 3D model in gaze-directed video},
 pages = {1--6},
 bookpagination = {page},
 booktitle = {Multimedia and Expo (ICME), 2011 IEEE International Conference on},
 year = {2011}
}


@proceedings{Thomas.1980,
 year = {1980},
 title = {Proceedings of the 7th annual conference on Computer graphics and interactive techniques},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {0897910214},
 editor = {Thomas, James J.},
 institution = {{ACM Special Interest Group on Computer Graphics and Interactive Techniques}},
 doi = {10.1145/800250}
}


@proceedings{Thomas.1991,
 year = {1991},
 title = {Proceedings of the 18th annual conference on Computer graphics and interactive techniques},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {0897914368},
 editor = {Thomas, James J.},
 institution = {{ACM Special Interest Group on Computer Graphics and Interactive Techniques}},
 doi = {10.1145/122718}
}


@misc{ThomasA.DeFanti.1977,
 author = {{Thomas A. DeFanti} and {Daniel J. Sandin}},
 date = {1977},
 title = {Final Report to the National Endownment of the Arts},
 urldate = {2017-10-12},
 number = {US NEA~R60-34-163},
 institution = {{University of Illinois}}
}


@proceedings{Tollmar.2008,
 year = {2008},
 title = {Proceedings of the 5th Nordic conference on Human-computer interaction building bridges},
 keywords = {Computer science},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {9781595937049},
 editor = {Tollmar, Konrad},
 doi = {10.1145/1463160}
}


@misc{VassilisAthitsos.2003,
 abstract = {A method is proposed that can generate a ranked list of plausible three-dimensional hand configurations that best match an input image. Hand pose estimation is formulated as an image database indexing problem, where the closest matches for an input hand image are retrieved from a large database of synthetic hand images. In contrast to previous approaches, the system can function in the presence of clutter, thanks to two novel clutter-tolerant indexing methods. First, a computationally efficient approximation of the image-to-model chamfer distance is obtained by embedding binary edge images into a high-dimensional Euclidean space. Second, a general-purpose, probabilistic line matching method identifies those line segment correspondences between model and input images that are the least likely to have occurred by chance. The performance ofthis cluttertolerant approach is demonstrated in quantitative experiments with hundreds ofreal hand images.},
 author = {{Vassilis Athitsos} and {Stan Sclaroff}},
 year = {2003},
 title = {Estimating 3D Hand Pose from a Cluttered Image},
 url = {http://ieeexplore.ieee.org/abstract/document/1211500/},
 urldate = {2017-08-13}
}


@inproceedings{Vlasic.2007,
 author = {Vlasic, Daniel and Adelsberger, Rolf and Vannucci, Giovanni and Barnwell, John and Gross, Markus and Matusik, Wojciech and Popovi{\'c}, Jovan},
 title = {Practical motion capture in everyday surroundings},
 pages = {35},
 bookpagination = {page},
 publisher = {ACM},
 isbn = {9781595936486},
 editor = {Levoy, Marc},
 booktitle = {SIGGRAPH 2007},
 year = {2007},
 address = {New York, NY},
 doi = {10.1145/1275808.1276421}
}


@article{Wampler.1986,
 author = {Wampler, Charles},
 year = {1986},
 title = {Manipulator Inverse Kinematic Solutions Based on Vector Formulations and Damped Least-Squares Methods},
 pages = {93--101},
 pagination = {page},
 volume = {16},
 number = {1},
 issn = {0018-9472},
 journal = {IEEE Transactions on Systems, Man, and Cybernetics},
 doi = {10.1109/TSMC.1986.289285}
}


@article{Wan.2014,
 author = {Wan, Jun and Ruan, Qiuqi and An, Gaoyun and Li, Wei and Liang, Yanyan and Zhao, Ruizhen},
 year = {2014},
 title = {The dynamic model embed in augmented graph cuts for robust hand tracking and segmentation in videos},
 volume = {2014},
 journal = {Mathematical Problems in Engineering}
}


@article{Wang.1991,
 author = {Wang, L.-C.T. and Chen, C. C.},
 year = {1991},
 title = {A combined optimization method for solving the inverse kinematics problems of mechanical manipulators},
 urldate = {2017-09-22},
 pages = {489--499},
 pagination = {page},
 volume = {7},
 number = {4},
 journal = {IEEE Transactions on Robotics and Automation},
 doi = {10.1109/70.86079}
}


@inproceedings{Wang.2009,
 author = {Wang, Robert Y. and Popovi{\'c}, Jovan},
 title = {Real-time hand-tracking with a color glove},
 pages = {63},
 bookpagination = {page},
 volume = {28},
 booktitle = {ACM transactions on graphics (TOG)},
 year = {2009}
}


@article{WayneWesterman.1999,
 author = {{Wayne Westerman}},
 year = {1999},
 title = {HAND TRACKING, FINGER IDENTIFICATION, AND CHORDIC MANIPULATION ON A MULTI-TOUCH SURFACE: A dissertation submitted to the Faculty of the University of Delaware in partial fulllment of the requirements for the degree of Doctor of Philosophy in Electrical Engineering},
 urldate = {2017-08-16}
}


@inproceedings{Weerasekera.2013,
 author = {Weerasekera, C. S. and Jaward, Mohamed Hisham and Kamrani, Nader},
 title = {Robust asl fingerspelling recognition using local binary patterns and geometric features},
 pages = {1--8},
 bookpagination = {page},
 booktitle = {Digital Image Computing: Techniques and Applications (DICTA), 2013 International Conference on},
 year = {2013}
}


@article{Welch.2002,
 author = {Welch, G. and Foxlin, E.},
 year = {2002},
 title = {Motion tracking: No silver bullet, but a respectable arsenal},
 pages = {24--38},
 pagination = {page},
 volume = {22},
 number = {6},
 issn = {02721716},
 journal = {IEEE Computer Graphics and Applications},
 doi = {10.1109/MCG.2002.1046626}
}


@article{Welman.,
 abstract = {Computer animation; Computer graphics; Kinematics -- Computer simulation.},
 author = {Welman, Chris.},
 year = {1989},
 title = {Inverse kinematics and geometric constraints for articulated figure manipulation},
 urldate = {2017-09-14}
}


@inproceedings{Wolovich.1984,
 author = {Wolovich, W. and Elliott, H.},
 title = {A computational technique for inverse kinematics},
 pages = {1359--1363},
 bookpagination = {page},
 publisher = {IEEE},
 booktitle = {The 23rd IEEE Conference on Decision and Control},
 year = {1984},
 doi = {10.1109/CDC.1984.272258}
}


@proceedings{WorkshoponHumanMotion.2000,
 year = {2000},
 title = {Proceedings, Workshop on Human Motion: 7-8 December 2000, Austin, Texas},
 price = {microfiche},
 keywords = {Automation;Computer simulation;Computer vision;Congresses;Data processing;Face perception;Gesture;Human locomotion;Kinesiology;Optical pattern recognition},
 address = {Los Alamitos, Calif},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-0939-8},
 institution = {{Workshop on Human Motion} and {IEEE Computer Society}}
}


@article{Wren.1997,
 author = {Wren, C. R. and Azarbayejani, A. and Darrell, T. and Pentland, A. P.},
 year = {1997},
 title = {Pfinder: Real-time tracking of the human body},
 pages = {780--785},
 pagination = {page},
 volume = {19},
 number = {7},
 issn = {01628828},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 doi = {10.1109/34.598236}
}


@article{Zhang.2000,
 author = {Zhang, Z.},
 year = {2000},
 title = {A flexible new technique for camera calibration},
 urldate = {2018-02-10},
 pages = {1330--1334},
 pagination = {page},
 volume = {22},
 number = {11},
 issn = {01628828},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 doi = {10.1109/34.888718}
}


@book{Zhang.2002,
 author = {Zhang, Xiang and Fronz, Stephan and Navab, Nassir},
 year = {2002},
 title = {Visual Marker Detection and Decoding in AR Systems: A Comparative Study: International Symposium on Mixed and Augmented Reality ISMAR 2002, September 30-October 1, 2002, Darmstadt, Germany : proceedings},
 keywords = {Computer graphics;Congresses;Human-computer interaction;Virtual reality;Visualization},
 address = {Los Almitos, Calif},
 urldate = {2017-10-05},
 publisher = {{IEEE Computer Society}},
 institution = {{IEEE and ACM International Symposium on Mixed and Augmented Reality} and {Association for Computing Machinery} and {Fraunhofer Institut Graphische Datenverarbeitung} and {IEEE Computer Society}}
}


@article{Zhang.2015,
 abstract = {Neurocomputing, 157 + (2015) 296-305. doi:10.1016/j.neucom.2015.01.002},
 author = {Zhang, Xiaoqin and Li, Wei and Ye, Xiuzi and Maybank, Stephen},
 year = {2015},
 title = {Robust hand tracking via novel multi-cue integration},
 keywords = {Feature selection;Hand tracking;Multi-cue integration;RCD},
 urldate = {2017-08-16},
 pages = {296--305},
 pagination = {page},
 volume = {157},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2015.01.002}
}


@article{Zhao.1994b,
 abstract = {An articulated figure is often modeled as a set of rigid segments connected with joints. Its configuration can be altered by varying the joint angles. Although it is straightforward to compute figure configurations given joint angles (forward kinematics), it is more difficult to find the joint angles for a desired configuration (inverse kinematics). Since the inverse kinematics problem is of special importance to an animator wishing to set a figure to a posture satisfying a set of positioning constraints, researchers have proposed several different approaches. However, when we try to follow these approaches in an interactive animation system where the object on which LOoperate is as highly articulated as a realistic human figure, they fail in either generality or performance. So, we approach this problem through nonlinear programming techniques. It has been successfully used since 1988 in the spatial constraint system within Jack {\grq}W,a human figure simulation system developed at the University of Pennsylvania, and proves to be satisfactorily eff]cient, controllable, and robust. A spatial constraint in our system involves two parts: one constraint on the figure, the end-eflector, and one on the spatial environment, the goal. These two parts are dealt with separately, so that wc can achieve a neat modular implementation. Constraints can be added one at a time with appropriate weights designating the importance of this constraint relative to the others and are always solved as a group. [f physical limits prevent satisfaction of all the constraints, the system stops with the (possibly local) optimal solution for the given weights. Also, the rigidity of each joint angle can be controlled, which is useful for redundant degrees of freedom.},
 author = {Zhao, Jianmin and Badler, Norman I.},
 year = {1994},
 title = {Inverse kinematics positioning using nonlinear programming for highly articulated figures},
 urldate = {2017-09-22},
 pages = {313--336},
 pagination = {page},
 volume = {13},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/195826.195827}
}


@article{Zhao.1994c,
 abstract = {An articulated figure is often modeled as a set of rigid segments connected with joints. Its configuration can be altered by varying the joint angles. Although it is straightforward to compute figure configurations given joint angles (forward kinematics), it is more difficult to find the joint angles for a desired configuration (inverse kinematics). Since the inverse kinematics problem is of special importance to an animator wishing to set a figure to a posture satisfying a set of positioning constraints, researchers have proposed several different approaches. However, when we try to follow these approaches in an interactive animation system where the object on which LOoperate is as highly articulated as a realistic human figure, they fail in either generality or performance. So, we approach this problem through nonlinear programming techniques. It has been successfully used since 1988 in the spatial constraint system within Jack {\grq}W,a human figure simulation system developed at the University of Pennsylvania, and proves to be satisfactorily eff]cient, controllable, and robust. A spatial constraint in our system involves two parts: one constraint on the figure, the end-eflector, and one on the spatial environment, the goal. These two parts are dealt with separately, so that wc can achieve a neat modular implementation. Constraints can be added one at a time with appropriate weights designating the importance of this constraint relative to the others and are always solved as a group. [f physical limits prevent satisfaction of all the constraints, the system stops with the (possibly local) optimal solution for the given weights. Also, the rigidity of each joint angle can be controlled, which is useful for redundant degrees of freedom.},
 author = {Zhao, Jianmin and Badler, Norman I.},
 year = {1994},
 title = {Inverse kinematics positioning using nonlinear programming for highly articulated figures},
 urldate = {2017-09-22},
 pages = {313--336},
 pagination = {page},
 volume = {13},
 number = {4},
 issn = {07300301},
 journal = {ACM Transactions on Graphics},
 doi = {10.1145/195826.195827}
}


@article{Zhou.2008,
 abstract = {This paper presents a new human motion tracking system using two wearable inertial sensors that are placed near the wrist and elbow joints of the upper limb. Each inertial sensor consists of a tri-axial accelerometer, a tri-axial gyroscope and a tri-axial magnetometer. The turning rates of the gyroscope were utilised for localising the wrist and elbow joints on the assumption that the two upper limb segment lengths are known a priori. To determine the translation and rotation of the shoulder joint, an equality-constrained optimisation technique is adopted to find an optimal solution, incorporating measurements from the tri-axial accelerometer and gyroscope. Experimental results demonstrate that this new system, compared to an optical motion tracker, has RMS position errors that are normally less than 0.01 m, and RMS angle errors that are 2.5-4.8 degrees .},
 author = {Zhou, Huiyu and Stone, Thomas and Hu, Huosheng and Harris, Nigel},
 year = {2008},
 title = {Use of multiple wearable inertial sensors in upper limb motion tracking},
 keywords = {Acceleration;Adult;Biomechanical Phenomena/instrumentation;Elbow Joint/physiology;Elbow/physiology;Equipment Design;Equipment Failure Analysis;Humans;Magnetics/instrumentation;Male;Models, Biological;Monitoring, Ambulatory/instrumentation;Movement/physiology;Range of Motion, Articular;Reproducibility of Results;Rotation;Transducers;Wrist Joint/physiology;Wrist/physiology},
 pages = {123--133},
 pagination = {page},
 volume = {30},
 number = {1},
 issn = {1350-4533},
 journal = {Medical engineering {\&} physics},
 doi = {10.1016/j.medengphy.2006.11.010}
}


