%!TEX root = ../Masterthesis.tex
\chapter{System prequisites}

Befor elaborating a final system conception, some prequisites have to be defined.

System components to be defined:
\begin{itemize}
 \item Tracking Hardware
 \item Image analysis
 \item Inverse kinameatics algorithm
 \item Handmodel
 \item Display hardware 
 \end{itemize} 

 \section{Display}
 Before analyzing the other components of the system, the final display hardware   properties have to be defined as these are the determinig factor for all other components. Since the goal of hand and object tracking is mostly immersive when using a virtaul reality headset rather than a normal display, these do not need to be taken into consideration.\\
Another device category which may be in the focus of interest are current mobile device Plattforms like \textit{Google cardboard} or the \textit{Samsung Gear} plattform.In terms of creating an low cost consumer grade solution, these devvices should be the first catergory to look at, as they are more wiedely available and do not need extra hardware except the smartphone. Most modern devices have native suport of WebGL in the Browser, making it fairly easy to display VR Content. They also come with the convenience of already having a set of integrated sensors for position an rotation integrated. The downside of this device class apperas when taking a look at the hardware specifications of these devices. Although the newest high tier consumer grade devices do have a good performance output for their size,but still no comparison for a Desktop Setup. \todo {get device specs for current phones} Also these devices, as they are first of all mobile phones, lack in terms of connection ports, for wire connections, making it necessarry to mostly communicate over wireless protocols. This causes a growth in  Infrastructure (Server, Hotspot, etc.) and also introduces pyhsical delay through signal transmission.\\
After these first eliminary steps, only pure VR-Headsets like the \textit{HTC Vive} or \textit{Occulus Rift}\todo {get refs for devices}  should be the main focus. These headsets also provide the capabilites of motion tracking while utilizing the processing capabilites of a desicated GPU and highpower CPU capabilities of modern desktop computers. Through these, they provide a variety of connection ports for wired connections, eliminating the need for wireless transmissions. In terms of cost, these devices do lie on the more costly side as you need the headset itsself and a hardware setup which is capable of providing the output framerate needed. But with the latest generations of GPU's and CPU's, reaching this goal was mafde possible for the normal consumer.\\
The \textit{HTC Vive} \todo {Occulus specs}  is able to display 90 Images per second on both of its displays with each having a resolution of 1080x1200 pixels\todo{ref}. The duration of one frame is therfore around 10 ms. This is the timeframe in which the rest of the componets have to supply the image data, do the image analysis to retrieve the tracking data, recalculate the IK model, calculate the object positon and render the whole scene.

\section{Tracking Hardware}
 As explained int the previous chapters, the motion of the human hand can be complex and in some cases realy fast. Therefore, the optical tracking hardware should idealy be able to record images with the same or higher frequency as the display medium that is to be used. Prosumer and professional grade cameras are theoretically able to produce these kind of Framerates (60 fps and above), but most of the time store these high framerate videos directly to a hard drive rather than broadcasting them somewhere as most of the current day devices are not able to display such high framerates yet. Also the hardware that is needed to record such specific high framerates is relatively expensive. Consumer grade cameras like the GoPro that are affordable, can record at a Framerate of 120 fps but the live transmission of this material has a time lack of several frames.\\
\\When trying to utilize low cost hardware the limitation of recording and sending a video signal from a camera to a processing hardware will therfore be limited to 60fps. This process would also introduce further latency on the transport and would force a further reduction of framerate to satify the timeframe given by the display framerate.
\\Another option that can be taken into consideration is to completely eliminate the need to transport the image data from camera to another device. This can be achieved when the camera and the computational hardware are located on the same hardware.\\The \textit{Rapsberry Pi 3} microcomputer, which comes from the internet of things world provides this capability. It combines a for its size quite powerfull computation capacity with an onboard hardware connector for a camera. The camera is able to record in a FullHD resolution at 60fps and at lower resolutions up to 90fps. The camera module is dircetly connected on the the chipboard, providing direct access for further processing.\\
For a complete 3 Dimmension space tracking, a one camera setup is not sufficient as it lack the data for the depth position of the object. To get this data, further hardware is needed. One option would be the utilization of a time of light based depth sensing system, but these system do come at a rather high entry level price.\todo {prices and lit}
\\Another option could be the tracking  pods thath HTC offers as an expansion to ist vive system. These trackers could provide 3d positional Data but with the downside of beeing relatively bulky. This would hinder the movement space of the hand and the tracker would have to be positioned on the arm as near as possible to the wrist. This would result in the position of only the wrist and not providing data on each individual finger of the hand.\\
As the hardware setup of the Rapsberry Pi with the camera is realtively easy and cost efficient, the usage of a second Raspberry Pi with a camera is good leverage point. The two cameras can be setup to create a stereoscopic Camera setup which provides information about depth position through the disparity of the two camera images. 
Furthermore  the image operations that need to be independantly applied to each of the cameras frames can be done on the two sperate device, eliminating the need for sending data trafic with image informaton through the network for postprocessing.
\\Downside of this method is thath with all Stereoscopic camera Setups, the two cameras need to have some kind of frame synchronization to get the right two frames for evaluation.
\\As the setup is not only meant for tracking the hand, but also for tracking objects in the tracking space, the system needs to be capable to do this task as well. Since the computatonal power of the raspberry is limited at some point, it is to be evaluated if a seperate hardware component is needed for teh object tracking or if the tracking can be integrated into the tracking procedure of the hand markers. Another question that has to be investigated would be, how important the depth position for the to be tracked object really is as they will not be floating in space while beeing tracked. Maybe a combination of hand position data and object orientation can already function as a suitable taracking method.







\section{image analysis}
The images recorded by the camaera system need to be processed further down the line to get the positional data of selected hand features. The most common library to do such kinds of image processing is the opencv library which is originally written in C and was ported into several other programming languages. It has build in features for camera calibration, color and object detection as well as several image optimization features that might be helpfull for the processing.
\section{inverse kinematics}
The inverse kinematics model is the second essential part of the setup after the tracking Hardware. It recieves the position data from the image postprocessing and calulates the resulting current hand model position.
\cite{Lansley.2016}
\section{handmodel}
 