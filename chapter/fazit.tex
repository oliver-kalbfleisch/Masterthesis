\chapter{Future Work}
The system evaluation showed that the principal functionality of the tracking system can be established with the selected components. One major point of improvement that could be applied to the system would be improvements to the used camera control framework. At the current state, a max frame rate of only 30 FPS readout is reachable while the hardware is theoretically able to supply up to 90 FPS readout. 
Large parts of the processing time on the raspberry side are accounted for by costly image optimization like blurring or transformations. These operations on whole images are classical candidates to be outsourced onto the GPU of the Raspberry for faster computation. A conversion of the existing OpenCV code into the assembler-like code for the raspberry GPU should be a future goal.\\
The calculation results for the depth values were already improved through the correction formula. To get even better results, a measurement session with more measurement points should be done to improve the values furthermore.
The color threshold, which is done by OpenCV, could also be optimized to threshold all colors in a single run instead of running an operation for each color. This could also be candidate for GPU outsourcing.
In the current state, a lot of values have to edited manually and are only visible on the command line. A graphical user interface should be build to ease the access.
The hand data that is used for prototyping is still hard coded and only manually configurable. A calibration procedure for the system as well as a suitable data format for representing and translating these values for the IK algorithm is still to be done.
\chapter{Conclusion}
The constructed prototype showed, that it is possible to construct a basic hand and object tracking system with consumer grade hard and software.The hardware capabilities of the used Raspberry Pi showed to be able to supply enough processing power to run live image processing operations. A downside of the used camera hardware is that the used sensor utilizes a rolling instead of a global shutter. This makes the synchronization of the two cameras for the stereoscopic setup harder. Furthermore, the cameras were not intended to be used in such a scenario, therefore they lack a frame synchronization feature. The only way of achieving a form of synchronization is on the software side.\\
Timing measurements showed that at lower frame rates, the described multi-threaded processing approach does not reach much higher processing times than the sequential approach. The sequential process is also less error prone since it does not need the additional synchronization wrappings that the multi-threaded approach needs. Should higher readout frame rates be achieved from the camera, the multi-threaded approach should definitely be used. At the selected resolution of 640x480 pixels, the system is able to track 6 color markers at around 50 fps max.
The selection of the usable color markers is rather limited. Colors from the orange yellow and red color spectrum showed to be rather difficult to track. The reflections that can occur when the hand is moved inside the tracking space can fall into these color ranges. This introduces an unwanted error in the marker position calculation.
Shrink tubing, although being easy to adapt to finger sizes showed to have the downside of not being available in the needed tracking colors.The selected application of acrylic paint to the fingers as color markers has the benefit of being available in a wide variety of colors. It is also the least restricting type of all used markers in terms of haptics.

The used inverse kinematics framework is  a good starting point for the display of the digital hand model.It does lack some features like inter-finger and parabolic constraints which would better match the final result to the real world hand position.

